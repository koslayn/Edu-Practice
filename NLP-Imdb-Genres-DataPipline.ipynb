{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "634a7d37",
   "metadata": {
    "papermill": {
     "duration": 0.016498,
     "end_time": "2022-08-05T11:41:20.954654",
     "exception": false,
     "start_time": "2022-08-05T11:41:20.938156",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Подготовка данных для обучения сети"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81ab584",
   "metadata": {
    "papermill": {
     "duration": 0.012976,
     "end_time": "2022-08-05T11:41:20.981011",
     "exception": false,
     "start_time": "2022-08-05T11:41:20.968035",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Заметки по bash:\n",
    "* `rm -rf './model'` - удалить папку\n",
    "* `rm ./data/train_Sample150k_Vac134k_Seq256.tfrecords` - удалить файл\n",
    "* `mv что_переместить куда_переместить`\n",
    "* `!ls -all ./data` - показать файлы и дополнительную информацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "774e6eb4",
   "metadata": {
    "_cell_guid": "58d3164c-ab86-4545-b568-98fde0eaa829",
    "_uuid": "72de40aa-4ac3-436d-a993-7fe508764ef5",
    "execution": {
     "iopub.execute_input": "2022-08-05T11:41:21.009471Z",
     "iopub.status.busy": "2022-08-05T11:41:21.009027Z",
     "iopub.status.idle": "2022-08-05T11:41:27.348690Z",
     "shell.execute_reply": "2022-08-05T11:41:27.347512Z"
    },
    "papermill": {
     "duration": 6.357231,
     "end_time": "2022-08-05T11:41:27.351487",
     "exception": false,
     "start_time": "2022-08-05T11:41:20.994256",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.utils import class_weight\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9644199",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-05T11:41:27.381909Z",
     "iopub.status.busy": "2022-08-05T11:41:27.380723Z",
     "iopub.status.idle": "2022-08-05T11:41:27.386564Z",
     "shell.execute_reply": "2022-08-05T11:41:27.385618Z"
    },
    "papermill": {
     "duration": 0.023818,
     "end_time": "2022-08-05T11:41:27.388742",
     "exception": false,
     "start_time": "2022-08-05T11:41:27.364924",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "HP_DATASET = {'dataset_size_resampled' : 500_000,\n",
    "              'max_features'           : 50_000,\n",
    "              'max_sequence_length'    : 128,\n",
    "              'batch_size'             : 2048,\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e81ff34a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-05T11:41:27.417535Z",
     "iopub.status.busy": "2022-08-05T11:41:27.416693Z",
     "iopub.status.idle": "2022-08-05T11:41:27.423428Z",
     "shell.execute_reply": "2022-08-05T11:41:27.422504Z"
    },
    "papermill": {
     "duration": 0.024116,
     "end_time": "2022-08-05T11:41:27.425979",
     "exception": false,
     "start_time": "2022-08-05T11:41:27.401863",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_data = Path('./data/')\n",
    "path_models = Path('./models/')\n",
    "\n",
    "filename_train_cleaned                         = f\"train_cleaned.tfrecords\"\n",
    "filename_train_clean_encoded                   = f\"train_clean_encoded.tfrecords\"\n",
    "filename_train_clean_encode_resampled          = f\"train_clean_encode_resampled.tfrecords\"\n",
    "\n",
    "\n",
    "filename_test_cleaned                          = f\"test_cleaned.tfrecords\"\n",
    "filename_test_clean_encoded                    = f\"test_clean_encoded.tfrecords\"\n",
    "\n",
    "filename_model_int_vect                        = f\"int_vect_layer_75k_128e\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "421e9006",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-05T11:41:27.458807Z",
     "iopub.status.busy": "2022-08-05T11:41:27.458404Z",
     "iopub.status.idle": "2022-08-05T11:41:27.466259Z",
     "shell.execute_reply": "2022-08-05T11:41:27.464714Z"
    },
    "papermill": {
     "duration": 0.02566,
     "end_time": "2022-08-05T11:41:27.469494",
     "exception": false,
     "start_time": "2022-08-05T11:41:27.443834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder `data` was create\n",
      "Folder `models` was create\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(path_data):\n",
    "    pass\n",
    "else:\n",
    "    os.makedirs(path_data)\n",
    "    print('Folder `data` was create')\n",
    "\n",
    "    \n",
    "if os.path.exists(path_models):\n",
    "    pass\n",
    "else:\n",
    "    os.makedirs(path_models)\n",
    "    print('Folder `models` was create')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb99c8c",
   "metadata": {
    "papermill": {
     "duration": 0.013009,
     "end_time": "2022-08-05T11:41:27.497304",
     "exception": false,
     "start_time": "2022-08-05T11:41:27.484295",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1 Загрузка txt в Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a249df53",
   "metadata": {
    "_cell_guid": "d4572df9-324b-4b53-a9fe-36f7781702ad",
    "_uuid": "32aa408a-e01f-4792-843e-59d95164f279",
    "execution": {
     "iopub.execute_input": "2022-08-05T11:41:27.529595Z",
     "iopub.status.busy": "2022-08-05T11:41:27.528867Z",
     "iopub.status.idle": "2022-08-05T11:41:27.535445Z",
     "shell.execute_reply": "2022-08-05T11:41:27.534658Z"
    },
    "papermill": {
     "duration": 0.024534,
     "end_time": "2022-08-05T11:41:27.537449",
     "exception": false,
     "start_time": "2022-08-05T11:41:27.512915",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_data(path_filename):\n",
    "  # Создание текстового dataset считывает указанный файл\n",
    "  dataset = tf.data.TextLineDataset([path_filename])\n",
    "  # Разделение записей (строка) на элементы по разделителю\n",
    "  dataset = dataset.map(lambda x: tf.strings.split(x, ' ::: '))\n",
    "  # Разделение на отдельных \"записей\" - изменение размерности (4, ) -> (4, 1)\n",
    "  dataset = dataset.map(lambda x: tf.stack(tf.split(x, num_or_size_splits=4)))\n",
    "  # фильтр полей - остаются только жанр и описание\n",
    "  # можно построить словарь и в дальнейшем обращаться к нужной части\n",
    "  dataset = dataset.map(lambda x: {'label': x[2][0], 'text': x[3][0]})\n",
    "  return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89681d70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-05T11:41:27.565841Z",
     "iopub.status.busy": "2022-08-05T11:41:27.565082Z",
     "iopub.status.idle": "2022-08-05T11:41:27.999845Z",
     "shell.execute_reply": "2022-08-05T11:41:27.998010Z"
    },
    "papermill": {
     "duration": 0.45178,
     "end_time": "2022-08-05T11:41:28.002353",
     "exception": false,
     "start_time": "2022-08-05T11:41:27.550573",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-05 11:41:27.582951: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': <tf.Tensor: shape=(), dtype=string, numpy=b'drama'>, 'text': <tf.Tensor: shape=(), dtype=string, numpy=b'Listening in to a conversation between his doctor and parents, 10-year-old Oscar learns what nobody has the courage to tell him. He only has a few weeks to live. Furious, he refuses to speak to anyone except straight-talking Rose, the lady in pink he meets on the hospital stairs. As Christmas approaches, Rose uses her fantastical experiences as a professional wrestler, her imagination, wit and charm to allow Oscar to live life and love to the full, in the company of his friends Pop Corn, Einstein, Bacon and childhood sweetheart Peggy Blue.'>}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-05 11:41:27.824742: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    }
   ],
   "source": [
    "# Загрузка и разделение на описание и лейблы\n",
    "path_train_data = '../input/genre-classification-dataset-imdb/Genre Classification Dataset/train_data.txt'\n",
    "\n",
    "train_ds = load_data(path_train_data)\n",
    "\n",
    "for i in train_ds.take(1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d68b6a3",
   "metadata": {
    "papermill": {
     "duration": 0.013887,
     "end_time": "2022-08-05T11:41:28.030385",
     "exception": false,
     "start_time": "2022-08-05T11:41:28.016498",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2 Кодирование жанров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e310e5d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-05T11:41:28.061074Z",
     "iopub.status.busy": "2022-08-05T11:41:28.060223Z",
     "iopub.status.idle": "2022-08-05T11:41:28.070459Z",
     "shell.execute_reply": "2022-08-05T11:41:28.069310Z"
    },
    "papermill": {
     "duration": 0.027861,
     "end_time": "2022-08-05T11:41:28.072582",
     "exception": false,
     "start_time": "2022-08-05T11:41:28.044721",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def encode_label(dataset):\n",
    "  # Создание словаря \\ таблицы для кодирования классов\n",
    "  # Для этого используется статичный \"словарь\" - таблица.\n",
    "  init = tf.lookup.KeyValueTensorInitializer(\n",
    "      keys=tf.constant([b'drama', b'thriller', b'adult', b'documentary', b'comedy',\n",
    "                        b'crime', b'reality-tv', b'horror', b'sport', b'animation',\n",
    "                        b'action', b'fantasy', b'short', b'sci-fi', b'music', b'adventure',\n",
    "                        b'talk-show', b'western', b'family', b'mystery', b'history',\n",
    "                        b'news', b'biography', b'romance', b'game-show', b'musical', b'war']),\n",
    "      values=tf.constant([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, \n",
    "                          17, 18, 19, 20, 21, 22, 23, 24, 25, 26, ], dtype=tf.int64))\n",
    "\n",
    "  table = tf.lookup.StaticVocabularyTable(init, num_oov_buckets=5)\n",
    "\n",
    "  # Заменяем жанры на цифры - применяем полученную таблицу к жанрам.\n",
    "  # Сейчас записи сохранены в виде словаря\n",
    "  \n",
    "  return (dataset['text'], table[dataset['label']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27cfba23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-05T11:41:28.101722Z",
     "iopub.status.busy": "2022-08-05T11:41:28.101053Z",
     "iopub.status.idle": "2022-08-05T11:41:28.326658Z",
     "shell.execute_reply": "2022-08-05T11:41:28.325338Z"
    },
    "papermill": {
     "duration": 0.243206,
     "end_time": "2022-08-05T11:41:28.329058",
     "exception": false,
     "start_time": "2022-08-05T11:41:28.085852",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'Listening in to a conversation between his doctor and parents, 10-year-old Oscar learns what nobody has the courage to tell him. He only has a few weeks to live. Furious, he refuses to speak to anyone except straight-talking Rose, the lady in pink he meets on the hospital stairs. As Christmas approaches, Rose uses her fantastical experiences as a professional wrestler, her imagination, wit and charm to allow Oscar to live life and love to the full, in the company of his friends Pop Corn, Einstein, Bacon and childhood sweetheart Peggy Blue.'>, <tf.Tensor: shape=(), dtype=int64, numpy=0>)\n"
     ]
    }
   ],
   "source": [
    "# Кодирование лейблов (жанров)\n",
    "train_ds = train_ds.map(encode_label)\n",
    "for i in train_ds.take(1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0257217",
   "metadata": {
    "papermill": {
     "duration": 0.01314,
     "end_time": "2022-08-05T11:41:28.355776",
     "exception": false,
     "start_time": "2022-08-05T11:41:28.342636",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 3 Очистка текста от stop слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20f80064",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-05T11:41:28.385730Z",
     "iopub.status.busy": "2022-08-05T11:41:28.384396Z",
     "iopub.status.idle": "2022-08-05T11:41:29.235591Z",
     "shell.execute_reply": "2022-08-05T11:41:29.234293Z"
    },
    "papermill": {
     "duration": 0.869443,
     "end_time": "2022-08-05T11:41:29.238467",
     "exception": false,
     "start_time": "2022-08-05T11:41:28.369024",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopwords_eng = stopwords.words('english')\n",
    "\n",
    "def clean_data(dataset, stop_words):\n",
    "    punctuation = \"\"\"[!\"#$%&'()*+,./:;<=>?@[\\]^_`{|}~]\"\"\"\n",
    "    doc, label = dataset\n",
    "    # приведение к нижнему регистру\n",
    "    doc = tf.strings.lower(doc)\n",
    "    # заменяем `-` для отдельных слов, чтобы не сливалось 10year\n",
    "    doc = tf.strings.regex_replace(doc, '-', ' ', replace_global=True, name=None)\n",
    "    # замена всей пунктуации\n",
    "    doc = tf.strings.regex_replace(doc, punctuation, '', replace_global=True, name=None)\n",
    "    for word in stop_words:\n",
    "        # замена стоп слов, слово целиком\n",
    "        doc = tf.strings.regex_replace(doc, f'\\\\b{word}\\\\b', ' ', replace_global=True, name=None)\n",
    "        # лишние пробелы после предыдущей замены\n",
    "        doc = tf.strings.regex_replace(doc, f' +', ' ', replace_global=True, name=None)\n",
    "        # пробелы вначале и конце тензора\n",
    "        doc = tf.strings.strip(doc, name=None)\n",
    "    return doc, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96242ebc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-05T11:41:29.267391Z",
     "iopub.status.busy": "2022-08-05T11:41:29.266628Z",
     "iopub.status.idle": "2022-08-05T11:41:30.026700Z",
     "shell.execute_reply": "2022-08-05T11:41:30.024983Z"
    },
    "papermill": {
     "duration": 0.778528,
     "end_time": "2022-08-05T11:41:30.030430",
     "exception": false,
     "start_time": "2022-08-05T11:41:29.251902",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function clean_data at 0x7f3ceb2c7c20> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Inconsistent ASTs detected. This is a bug. Cause: \n",
      "inconsistent values for field value: \\b and \bDiff:\n",
      "*** Original nodes\n",
      "\n",
      "--- Reparsed nodes\n",
      "\n",
      "***************\n",
      "\n",
      "*** 521,541 ****\n",
      "\n",
      "  | | | | | | | | | | | names=[\n",
      "  | | | | | | | | | | | | \"doc\"\n",
      "  | | | | | | | | | | | ]\n",
      "  | | | | | | | | | | Assign:\n",
      "  | | | | | | | | | | | targets=[\n",
      "  | | | | | | | | | | | | Name:\n",
      "  | | | | | | | | | | | | | id=u\"word\"\n",
      "! | | | | | | | | | | | | | ctx=Store:\n",
      "  | | | | | | | | | | | | | annotation=None\n",
      "  | | | | | | | | | | | | | type_comment=None\n",
      "  | | | | | | | | | | | ]\n",
      "  | | | | | | | | | | | value=Name:\n",
      "  | | | | | | | | | | | | id=u\"itr\"\n",
      "! | | | | | | | | | | | | ctx=Load:\n",
      "  | | | | | | | | | | | | annotation=None\n",
      "  | | | | | | | | | | | | type_comment=None\n",
      "  | | | | | | | | | | Assign:\n",
      "  | | | | | | | | | | | targets=[\n",
      "  | | | | | | | | | | | | Name:\n",
      "  | | | | | | | | | | | | | id=u\"doc\"\n",
      "  | | | | | | | | | | | | | ctx=Store()\n",
      "--- 521,541 ----\n",
      "\n",
      "  | | | | | | | | | | | names=[\n",
      "  | | | | | | | | | | | | \"doc\"\n",
      "  | | | | | | | | | | | ]\n",
      "  | | | | | | | | | | Assign:\n",
      "  | | | | | | | | | | | targets=[\n",
      "  | | | | | | | | | | | | Name:\n",
      "  | | | | | | | | | | | | | id=u\"word\"\n",
      "! | | | | | | | | | | | | | ctx=Store()\n",
      "  | | | | | | | | | | | | | annotation=None\n",
      "  | | | | | | | | | | | | | type_comment=None\n",
      "  | | | | | | | | | | | ]\n",
      "  | | | | | | | | | | | value=Name:\n",
      "  | | | | | | | | | | | | id=u\"itr\"\n",
      "! | | | | | | | | | | | | ctx=Load()\n",
      "  | | | | | | | | | | | | annotation=None\n",
      "  | | | | | | | | | | | | type_comment=None\n",
      "  | | | | | | | | | | Assign:\n",
      "  | | | | | | | | | | | targets=[\n",
      "  | | | | | | | | | | | | Name:\n",
      "  | | | | | | | | | | | | | id=u\"doc\"\n",
      "  | | | | | | | | | | | | | ctx=Store()\n",
      "***************\n",
      "\n",
      "*** 593,607 ****\n",
      "\n",
      "  | | | | | | | | | | | | | | | | | | annotation=None\n",
      "  | | | | | | | | | | | | | | | | | | type_comment=None\n",
      "  | | | | | | | | | | | | | | | | ]\n",
      "  | | | | | | | | | | | | | | | | keywords=[]\n",
      "  | | | | | | | | | | | | | | | JoinedStr:\n",
      "  | | | | | | | | | | | | | | | | values=[\n",
      "  | | | | | | | | | | | | | | | | | Constant:\n",
      "! | | | | | | | | | | | | | | | | | | value=u\"\\b\"\n",
      "  | | | | | | | | | | | | | | | | | | kind=None\n",
      "  | | | | | | | | | | | | | | | | | FormattedValue:\n",
      "  | | | | | | | | | | | | | | | | | | value=Call:\n",
      "  | | | | | | | | | | | | | | | | | | | func=Attribute:\n",
      "  | | | | | | | | | | | | | | | | | | | | value=Name:\n",
      "  | | | | | | | | | | | | | | | | | | | | | id=u\"ag__\"\n",
      "  | | | | | | | | | | | | | | | | | | | | | ctx=Load()\n",
      "--- 593,607 ----\n",
      "\n",
      "  | | | | | | | | | | | | | | | | | | annotation=None\n",
      "  | | | | | | | | | | | | | | | | | | type_comment=None\n",
      "  | | | | | | | | | | | | | | | | ]\n",
      "  | | | | | | | | | | | | | | | | keywords=[]\n",
      "  | | | | | | | | | | | | | | | JoinedStr:\n",
      "  | | | | | | | | | | | | | | | | values=[\n",
      "  | | | | | | | | | | | | | | | | | Constant:\n",
      "! | | | | | | | | | | | | | | | | | | value=u\"\b\"\n",
      "  | | | | | | | | | | | | | | | | | | kind=None\n",
      "  | | | | | | | | | | | | | | | | | FormattedValue:\n",
      "  | | | | | | | | | | | | | | | | | | value=Call:\n",
      "  | | | | | | | | | | | | | | | | | | | func=Attribute:\n",
      "  | | | | | | | | | | | | | | | | | | | | value=Name:\n",
      "  | | | | | | | | | | | | | | | | | | | | | id=u\"ag__\"\n",
      "  | | | | | | | | | | | | | | | | | | | | | ctx=Load()\n",
      "***************\n",
      "\n",
      "*** 616,630 ****\n",
      "\n",
      "  | | | | | | | | | | | | | | | | | | | | | annotation=None\n",
      "  | | | | | | | | | | | | | | | | | | | | | type_comment=None\n",
      "  | | | | | | | | | | | | | | | | | | | ]\n",
      "  | | | | | | | | | | | | | | | | | | | keywords=[]\n",
      "  | | | | | | | | | | | | | | | | | | conversion=-1\n",
      "  | | | | | | | | | | | | | | | | | | format_spec=None\n",
      "  | | | | | | | | | | | | | | | | | Constant:\n",
      "! | | | | | | | | | | | | | | | | | | value=u\"\\b\"\n",
      "  | | | | | | | | | | | | | | | | | | kind=None\n",
      "  | | | | | | | | | | | | | | | | ]\n",
      "  | | | | | | | | | | | | | | | Constant:\n",
      "  | | | | | | | | | | | | | | | | value=u\" \"\n",
      "  | | | | | | | | | | | | | | | | kind=None\n",
      "  | | | | | | | | | | | | | | ]\n",
      "  | | | | | | | | | | | | | | ctx=Load()\n",
      "--- 616,630 ----\n",
      "\n",
      "  | | | | | | | | | | | | | | | | | | | | | annotation=None\n",
      "  | | | | | | | | | | | | | | | | | | | | | type_comment=None\n",
      "  | | | | | | | | | | | | | | | | | | | ]\n",
      "  | | | | | | | | | | | | | | | | | | | keywords=[]\n",
      "  | | | | | | | | | | | | | | | | | | conversion=-1\n",
      "  | | | | | | | | | | | | | | | | | | format_spec=None\n",
      "  | | | | | | | | | | | | | | | | | Constant:\n",
      "! | | | | | | | | | | | | | | | | | | value=u\"\b\"\n",
      "  | | | | | | | | | | | | | | | | | | kind=None\n",
      "  | | | | | | | | | | | | | | | | ]\n",
      "  | | | | | | | | | | | | | | | Constant:\n",
      "  | | | | | | | | | | | | | | | | value=u\" \"\n",
      "  | | | | | | | | | | | | | | | | kind=None\n",
      "  | | | | | | | | | | | | | | ]\n",
      "  | | | | | | | | | | | | | | ctx=Load()\n",
      "***************\n",
      "\n",
      "*** 862,880 ****\n",
      "\n",
      "  | | | | | | | | | | ]\n",
      "  | | | | | | | | | | keywords=[]\n",
      "  | | | | | | | | Expr:\n",
      "  | | | | | | | | | value=Call:\n",
      "  | | | | | | | | | | func=Attribute:\n",
      "  | | | | | | | | | | | value=Name:\n",
      "  | | | | | | | | | | | | id=u\"ag__\"\n",
      "! | | | | | | | | | | | | ctx=Load:\n",
      "  | | | | | | | | | | | | annotation=None\n",
      "  | | | | | | | | | | | | type_comment=None\n",
      "  | | | | | | | | | | | attr=u\"for_stmt\"\n",
      "! | | | | | | | | | | | ctx=Load:\n",
      "  | | | | | | | | | | args=[\n",
      "  | | | | | | | | | | | Call:\n",
      "  | | | | | | | | | | | | func=Attribute:\n",
      "  | | | | | | | | | | | | | value=Name:\n",
      "  | | | | | | | | | | | | | | id=u\"ag__\"\n",
      "  | | | | | | | | | | | | | | ctx=Load()\n",
      "  | | | | | | | | | | | | | | annotation=None\n",
      "--- 862,880 ----\n",
      "\n",
      "  | | | | | | | | | | ]\n",
      "  | | | | | | | | | | keywords=[]\n",
      "  | | | | | | | | Expr:\n",
      "  | | | | | | | | | value=Call:\n",
      "  | | | | | | | | | | func=Attribute:\n",
      "  | | | | | | | | | | | value=Name:\n",
      "  | | | | | | | | | | | | id=u\"ag__\"\n",
      "! | | | | | | | | | | | | ctx=Load()\n",
      "  | | | | | | | | | | | | annotation=None\n",
      "  | | | | | | | | | | | | type_comment=None\n",
      "  | | | | | | | | | | | attr=u\"for_stmt\"\n",
      "! | | | | | | | | | | | ctx=Load()\n",
      "  | | | | | | | | | | args=[\n",
      "  | | | | | | | | | | | Call:\n",
      "  | | | | | | | | | | | | func=Attribute:\n",
      "  | | | | | | | | | | | | | value=Name:\n",
      "  | | | | | | | | | | | | | | id=u\"ag__\"\n",
      "  | | | | | | | | | | | | | | ctx=Load()\n",
      "  | | | | | | | | | | | | | | annotation=None\n",
      "***************\n",
      "\n",
      "*** 890,923 ****\n",
      "\n",
      "  | | | | | | | | | | | | ]\n",
      "  | | | | | | | | | | | | keywords=[]\n",
      "  | | | | | | | | | | | Constant:\n",
      "  | | | | | | | | | | | | value=None\n",
      "  | | | | | | | | | | | | kind=None\n",
      "  | | | | | | | | | | | Name:\n",
      "  | | | | | | | | | | | | id=u\"loop_body\"\n",
      "! | | | | | | | | | | | | ctx=Load:\n",
      "  | | | | | | | | | | | | annotation=None\n",
      "  | | | | | | | | | | | | type_comment=None\n",
      "  | | | | | | | | | | | Name:\n",
      "  | | | | | | | | | | | | id=u\"get_state\"\n",
      "! | | | | | | | | | | | | ctx=Load:\n",
      "  | | | | | | | | | | | | annotation=None\n",
      "  | | | | | | | | | | | | type_comment=None\n",
      "  | | | | | | | | | | | Name:\n",
      "  | | | | | | | | | | | | id=u\"set_state\"\n",
      "! | | | | | | | | | | | | ctx=Load:\n",
      "  | | | | | | | | | | | | annotation=None\n",
      "  | | | | | | | | | | | | type_comment=None\n",
      "  | | | | | | | | | | | Tuple:\n",
      "  | | | | | | | | | | | | elts=[\n",
      "  | | | | | | | | | | | | | Constant:\n",
      "  | | | | | | | | | | | | | | value=u\"doc\"\n",
      "  | | | | | | | | | | | | | | kind=None\n",
      "  | | | | | | | | | | | | ]\n",
      "! | | | | | | | | | | | | ctx=Load:\n",
      "  | | | | | | | | | | | Dict:\n",
      "  | | | | | | | | | | | | keys=[\n",
      "  | | | | | | | | | | | | | Constant:\n",
      "  | | | | | | | | | | | | | | value=u\"iterate_names\"\n",
      "  | | | | | | | | | | | | | | kind=None\n",
      "  | | | | | | | | | | | | ]\n",
      "  | | | | | | | | | | | | values=[\n",
      "--- 890,923 ----\n",
      "\n",
      "  | | | | | | | | | | | | ]\n",
      "  | | | | | | | | | | | | keywords=[]\n",
      "  | | | | | | | | | | | Constant:\n",
      "  | | | | | | | | | | | | value=None\n",
      "  | | | | | | | | | | | | kind=None\n",
      "  | | | | | | | | | | | Name:\n",
      "  | | | | | | | | | | | | id=u\"loop_body\"\n",
      "! | | | | | | | | | | | | ctx=Load()\n",
      "  | | | | | | | | | | | | annotation=None\n",
      "  | | | | | | | | | | | | type_comment=None\n",
      "  | | | | | | | | | | | Name:\n",
      "  | | | | | | | | | | | | id=u\"get_state\"\n",
      "! | | | | | | | | | | | | ctx=Load()\n",
      "  | | | | | | | | | | | | annotation=None\n",
      "  | | | | | | | | | | | | type_comment=None\n",
      "  | | | | | | | | | | | Name:\n",
      "  | | | | | | | | | | | | id=u\"set_state\"\n",
      "! | | | | | | | | | | | | ctx=Load()\n",
      "  | | | | | | | | | | | | annotation=None\n",
      "  | | | | | | | | | | | | type_comment=None\n",
      "  | | | | | | | | | | | Tuple:\n",
      "  | | | | | | | | | | | | elts=[\n",
      "  | | | | | | | | | | | | | Constant:\n",
      "  | | | | | | | | | | | | | | value=u\"doc\"\n",
      "  | | | | | | | | | | | | | | kind=None\n",
      "  | | | | | | | | | | | | ]\n",
      "! | | | | | | | | | | | | ctx=Load()\n",
      "  | | | | | | | | | | | Dict:\n",
      "  | | | | | | | | | | | | keys=[\n",
      "  | | | | | | | | | | | | | Constant:\n",
      "  | | | | | | | | | | | | | | value=u\"iterate_names\"\n",
      "  | | | | | | | | | | | | | | kind=None\n",
      "  | | | | | | | | | | | | ]\n",
      "  | | | | | | | | | | | | values=[\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'listening conversation doctor parents 10 year old oscar learns nobody courage tell weeks live furious refuses speak anyone except straight talking rose lady pink meets hospital stairs christmas approaches rose uses fantastical experiences professional wrestler imagination wit charm allow oscar live life love full company friends pop corn einstein bacon childhood sweetheart peggy blue'>, <tf.Tensor: shape=(), dtype=int64, numpy=0>)\n"
     ]
    }
   ],
   "source": [
    "train_ds = train_ds.map(lambda *x: clean_data(x, stopwords_eng))\n",
    "\n",
    "for i in train_ds.take(1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6069f5f3",
   "metadata": {
    "papermill": {
     "duration": 0.014288,
     "end_time": "2022-08-05T11:41:30.060052",
     "exception": false,
     "start_time": "2022-08-05T11:41:30.045764",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4 Сохранение набора данных в TFRecords (после очистки)\n",
    "\n",
    "Создание набора данных и запись в TFRecords занимает много времени, операция проведена один, раз после используется подготовленный файл."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1fbd91",
   "metadata": {
    "papermill": {
     "duration": 0.013575,
     "end_time": "2022-08-05T11:41:30.087561",
     "exception": false,
     "start_time": "2022-08-05T11:41:30.073986",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Функции сохранения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d6b39f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-05T11:41:30.117446Z",
     "iopub.status.busy": "2022-08-05T11:41:30.117045Z",
     "iopub.status.idle": "2022-08-05T11:41:30.125996Z",
     "shell.execute_reply": "2022-08-05T11:41:30.124925Z"
    },
    "papermill": {
     "duration": 0.026843,
     "end_time": "2022-08-05T11:41:30.128479",
     "exception": false,
     "start_time": "2022-08-05T11:41:30.101636",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def int64_feature(label):\n",
    "  label = tf.train.Feature(int64_list=tf.train.Int64List(value=[label])) \n",
    "  return label\n",
    "\n",
    "\n",
    "def bytes_feature(description):\n",
    "  if isinstance(description, type(tf.constant(0))):\n",
    "    description = description.numpy()\n",
    "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[description]))\n",
    "\n",
    "\n",
    "def float_feature(value):\n",
    "  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "\n",
    "def create_record(description, label):\n",
    "    feature = {\n",
    "        'description': description,\n",
    "        'label': label\n",
    "      }\n",
    "    proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    return proto.SerializeToString()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09a1d5c",
   "metadata": {
    "papermill": {
     "duration": 0.013609,
     "end_time": "2022-08-05T11:41:30.157229",
     "exception": false,
     "start_time": "2022-08-05T11:41:30.143620",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Функции загрузки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6896a03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-05T11:41:30.188867Z",
     "iopub.status.busy": "2022-08-05T11:41:30.187861Z",
     "iopub.status.idle": "2022-08-05T11:41:30.195391Z",
     "shell.execute_reply": "2022-08-05T11:41:30.194435Z"
    },
    "papermill": {
     "duration": 0.026183,
     "end_time": "2022-08-05T11:41:30.197927",
     "exception": false,
     "start_time": "2022-08-05T11:41:30.171744",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_description = {\n",
    "    'description': tf.io.FixedLenFeature([], tf.string, default_value=''),\n",
    "    'label': tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
    "}\n",
    "\n",
    "def parse_function(example_proto):\n",
    "  parsed = tf.io.parse_single_example(example_proto, feature_description)\n",
    "  return (parsed['description'], parsed['label']) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1552dbd6",
   "metadata": {
    "papermill": {
     "duration": 0.014218,
     "end_time": "2022-08-05T11:41:30.227115",
     "exception": false,
     "start_time": "2022-08-05T11:41:30.212897",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Сохранение очищенных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1be0488",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-05T11:41:30.259639Z",
     "iopub.status.busy": "2022-08-05T11:41:30.258282Z",
     "iopub.status.idle": "2022-08-05T11:43:30.706706Z",
     "shell.execute_reply": "2022-08-05T11:43:30.705842Z"
    },
    "papermill": {
     "duration": 120.481359,
     "end_time": "2022-08-05T11:43:30.723318",
     "exception": false,
     "start_time": "2022-08-05T11:41:30.241959",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset сохранён: data/train_cleaned.tfrecords\n"
     ]
    }
   ],
   "source": [
    "path = str(path_data / filename_train_cleaned)\n",
    "\n",
    "with tf.io.TFRecordWriter(path) as writer:\n",
    "    \"\"\"dataset: \n",
    "       sample0 - text_description; \n",
    "       sample1 - label\n",
    "    \"\"\"\n",
    "    for sample in train_ds:\n",
    "        label = int64_feature(sample[1])\n",
    "        desc = bytes_feature(sample[0])\n",
    "        pr = create_record(desc, label)\n",
    "        writer.write(pr)\n",
    "    print(f'dataset сохранён: {path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9fad92",
   "metadata": {
    "papermill": {
     "duration": 0.013746,
     "end_time": "2022-08-05T11:43:30.751582",
     "exception": false,
     "start_time": "2022-08-05T11:43:30.737836",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Проверка загрузки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1719052",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-05T11:43:30.782157Z",
     "iopub.status.busy": "2022-08-05T11:43:30.781382Z",
     "iopub.status.idle": "2022-08-05T11:43:49.755055Z",
     "shell.execute_reply": "2022-08-05T11:43:49.753454Z"
    },
    "papermill": {
     "duration": 18.992392,
     "end_time": "2022-08-05T11:43:49.757950",
     "exception": false,
     "start_time": "2022-08-05T11:43:30.765558",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'listening conversation doctor parents 10 year old oscar learns nobody courage tell weeks live furious refuses speak anyone except straight talking rose lady pink meets hospital stairs christmas approaches rose uses fantastical experiences professional wrestler imagination wit charm allow oscar live life love full company friends pop corn einstein bacon childhood sweetheart peggy blue'>, <tf.Tensor: shape=(), dtype=int64, numpy=0>)\n",
      "Набор данных количество записей: 54214\n",
      "Количество слов (для словаря): 134252\n"
     ]
    }
   ],
   "source": [
    "path = str(path_data / filename_train_cleaned)\n",
    "\n",
    "train_ds = tf.data.TFRecordDataset(filenames = [path])\n",
    "train_ds = train_ds.map(parse_function)\n",
    "\n",
    "for i in train_ds.take(1):\n",
    "    print(i)\n",
    "\n",
    "d_len = []\n",
    "for i in train_ds:\n",
    "    d_len.append(i)\n",
    "\n",
    "print('Набор данных количество записей:', len(d_len))\n",
    "\n",
    "words_amount = []\n",
    "for i in train_ds:\n",
    "    str_desc = i[0].numpy().decode()\n",
    "    words_amount.extend(str_desc.split(' '))\n",
    "\n",
    "print('Количество слов (для словаря):', len(set(words_amount)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c651be",
   "metadata": {
    "papermill": {
     "duration": 0.013905,
     "end_time": "2022-08-05T11:43:49.786733",
     "exception": false,
     "start_time": "2022-08-05T11:43:49.772828",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Всего 134252 уникальных токена в наборе**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc37f01",
   "metadata": {
    "papermill": {
     "duration": 0.013599,
     "end_time": "2022-08-05T11:43:49.815256",
     "exception": false,
     "start_time": "2022-08-05T11:43:49.801657",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 5 Кодирование данных для обучения модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21ec547",
   "metadata": {
    "papermill": {
     "duration": 0.01377,
     "end_time": "2022-08-05T11:43:49.843280",
     "exception": false,
     "start_time": "2022-08-05T11:43:49.829510",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Векторизация описания фильма:\n",
    "* Создаётся словарь заданной длины.\n",
    "* Каждому слову присваивается номер.\n",
    "* Слова в описании заменяются номерами.\n",
    "* Если длина описания фильма больше указанной, то описание обрезается.\n",
    "* Если меньше то дополняется нулями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7029ab5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-05T11:43:49.873318Z",
     "iopub.status.busy": "2022-08-05T11:43:49.872621Z",
     "iopub.status.idle": "2022-08-05T11:43:49.879119Z",
     "shell.execute_reply": "2022-08-05T11:43:49.877909Z"
    },
    "papermill": {
     "duration": 0.024157,
     "end_time": "2022-08-05T11:43:49.881431",
     "exception": false,
     "start_time": "2022-08-05T11:43:49.857274",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_description_encoder(dataset, MAX_FEATURES, MAX_SEQUENCE_LENGTH):\n",
    "  # Слой препроцесинга. Инициализация\n",
    "  int_vectorize_layer = tf.keras.layers.TextVectorization(\n",
    "      max_tokens=MAX_FEATURES,\n",
    "      standardize = 'lower_and_strip_punctuation',\n",
    "      output_mode='int',\n",
    "      output_sequence_length=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "  # Оставляем только описание фильма (без меток жанров)\n",
    "  dataset = dataset.map(lambda f, l: f)\n",
    "\n",
    "  # \"обучение\" препроцессинга для кодирования\n",
    "  int_vectorize_layer.adapt(dataset)\n",
    "  return int_vectorize_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8fc68df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-05T11:43:49.912760Z",
     "iopub.status.busy": "2022-08-05T11:43:49.912351Z",
     "iopub.status.idle": "2022-08-05T11:44:24.944766Z",
     "shell.execute_reply": "2022-08-05T11:44:24.943562Z"
    },
    "papermill": {
     "duration": 35.051237,
     "end_time": "2022-08-05T11:44:24.947545",
     "exception": false,
     "start_time": "2022-08-05T11:43:49.896308",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ⚠️Загружается очищенный набор, БЕЗ балансировки\n",
    "path = str(path_data / filename_train_cleaned)\n",
    "\n",
    "train_ds = tf.data.TFRecordDataset(filenames = [path])\n",
    "train_ds = train_ds.map(parse_function)\n",
    "\n",
    "# Создание кодировщика текста\n",
    "int_vectorize_layer = get_description_encoder(train_ds, \n",
    "                                              MAX_FEATURES=HP_DATASET['max_features'], \n",
    "                                              MAX_SEQUENCE_LENGTH=HP_DATASET['max_sequence_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e180555",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-05T11:44:24.978525Z",
     "iopub.status.busy": "2022-08-05T11:44:24.977740Z",
     "iopub.status.idle": "2022-08-05T11:44:25.274266Z",
     "shell.execute_reply": "2022-08-05T11:44:25.272238Z"
    },
    "papermill": {
     "duration": 0.31453,
     "end_time": "2022-08-05T11:44:25.276732",
     "exception": false,
     "start_time": "2022-08-05T11:44:24.962202",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Текстовое описание:\n",
      "{'label': <tf.Tensor: shape=(), dtype=string, numpy=b'drama'>, 'text': <tf.Tensor: shape=(), dtype=string, numpy=b'Listening in to a conversation between his doctor and parents, 10-year-old Oscar learns what nobody has the courage to tell him. He only has a few weeks to live. Furious, he refuses to speak to anyone except straight-talking Rose, the lady in pink he meets on the hospital stairs. As Christmas approaches, Rose uses her fantastical experiences as a professional wrestler, her imagination, wit and charm to allow Oscar to live life and love to the full, in the company of his friends Pop Corn, Einstein, Bacon and childhood sweetheart Peggy Blue.'>}\n",
      "Кодирование:\n",
      "tf.Tensor(\n",
      "[ 5135     1     1     1  1916     1     1   423     1   123     1  2550\n",
      "   337     1  2186     1     1  1339     1   351     1     1     1     1\n",
      "     1     1  1044     1    51  4331     1   840     1  1344     1   755\n",
      "  1796     1  1307     1   682     1  4897     1   106     1     1   463\n",
      "  8694     1   741  2726  1307   768     1 10628   484     1     1   608\n",
      "  9057     1  1810  4918     1  3608     1  1792  2550     1    51     2\n",
      "     1    10     1     1   275     1     1   240     1     1    30  1073\n",
      " 12241 15162 12587     1   376  2971  7744  1173     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0], shape=(128,), dtype=int64)\n",
      "Декодирование первого слова:\n",
      "smiley\n"
     ]
    }
   ],
   "source": [
    "# Пример кодирования изначального текста\n",
    "path_train_data = '../input/genre-classification-dataset-imdb/Genre Classification Dataset/train_data.txt'\n",
    "example_ds = load_data(path_train_data)\n",
    "\n",
    "# 1 - неизвестные слова, 0 - padding\n",
    "for i in example_ds.take(1):\n",
    "  print('Текстовое описание:')\n",
    "  print(i)\n",
    "  print('Кодирование:')\n",
    "  print(int_vectorize_layer(i['text']))\n",
    "  print('Декодирование первого слова:')\n",
    "  print(int_vectorize_layer.get_vocabulary()[7001])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490c638c",
   "metadata": {
    "papermill": {
     "duration": 0.013966,
     "end_time": "2022-08-05T11:44:25.305410",
     "exception": false,
     "start_time": "2022-08-05T11:44:25.291444",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Кодирование и сохранение очищенных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "44aa5ea7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-05T11:44:25.336281Z",
     "iopub.status.busy": "2022-08-05T11:44:25.335557Z",
     "iopub.status.idle": "2022-08-05T11:44:25.340569Z",
     "shell.execute_reply": "2022-08-05T11:44:25.339832Z"
    },
    "papermill": {
     "duration": 0.022936,
     "end_time": "2022-08-05T11:44:25.342560",
     "exception": false,
     "start_time": "2022-08-05T11:44:25.319624",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def encode_description(dataset, int_vectorize_layer):\n",
    "  # Кодируем тренировочный dataset (текст)\n",
    "  def int_vectorize_text(*ds):\n",
    "    return int_vectorize_layer(ds[0]), ds[1]\n",
    "  \n",
    "  dataset = dataset.map(int_vectorize_text)\n",
    "  return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f349733",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-05T11:44:25.373185Z",
     "iopub.status.busy": "2022-08-05T11:44:25.372380Z",
     "iopub.status.idle": "2022-08-05T11:44:25.495123Z",
     "shell.execute_reply": "2022-08-05T11:44:25.493994Z"
    },
    "papermill": {
     "duration": 0.141069,
     "end_time": "2022-08-05T11:44:25.497876",
     "exception": false,
     "start_time": "2022-08-05T11:44:25.356807",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = str(path_data / filename_train_cleaned)\n",
    "\n",
    "train_ds = tf.data.TFRecordDataset(filenames = [path])\n",
    "train_ds = train_ds.map(parse_function)\n",
    "\n",
    "train_ds_encoded = encode_description(train_ds, int_vectorize_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0460ccb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-05T11:44:25.528389Z",
     "iopub.status.busy": "2022-08-05T11:44:25.527982Z",
     "iopub.status.idle": "2022-08-05T11:45:03.301500Z",
     "shell.execute_reply": "2022-08-05T11:45:03.300485Z"
    },
    "papermill": {
     "duration": 37.791984,
     "end_time": "2022-08-05T11:45:03.304235",
     "exception": false,
     "start_time": "2022-08-05T11:44:25.512251",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Сохранение на диск\n",
    "path = str(path_data / filename_train_clean_encoded)\n",
    "\n",
    "with tf.io.TFRecordWriter(path) as writer:\n",
    "    for sample in train_ds_encoded:\n",
    "        label = int64_feature(sample[1])\n",
    "        # Для преобразования в скаляр, array напрямую нельзя кодировать\n",
    "        desc_serialized = tf.io.serialize_tensor(sample[0])\n",
    "        desc = bytes_feature(desc_serialized)\n",
    "        pr = create_record(desc, label)\n",
    "        writer.write(pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e3186908",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-05T11:45:03.335461Z",
     "iopub.status.busy": "2022-08-05T11:45:03.335050Z",
     "iopub.status.idle": "2022-08-05T11:45:03.416317Z",
     "shell.execute_reply": "2022-08-05T11:45:03.414532Z"
    },
    "papermill": {
     "duration": 0.100766,
     "end_time": "2022-08-05T11:45:03.419880",
     "exception": false,
     "start_time": "2022-08-05T11:45:03.319114",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(128,), dtype=int64, numpy=\n",
      "array([ 5135,  1916,   423,   123,   677,    28,    16,  2550,   337,\n",
      "        2186,  1339,   351,  1044,    51,  4331,   840,  1344,   755,\n",
      "        1796,  1485,  1322,  1307,   682,  4897,   106,   463,  8694,\n",
      "         741,  2726,  1307,   768, 10628,   484,   608,  9057,  1810,\n",
      "        4918,  3608,  1792,  2550,    51,     2,    10,   275,   240,\n",
      "          30,  1073, 12241, 15162, 12587,   376,  2971,  7744,  1173,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0])>, <tf.Tensor: shape=(), dtype=int64, numpy=0>)\n"
     ]
    }
   ],
   "source": [
    "# Проверка \n",
    "path = str(path_data / filename_train_clean_encoded)\n",
    "\n",
    "train_ds = tf.data.TFRecordDataset(filenames = [path])\n",
    "train_ds = train_ds.map(parse_function)\n",
    "\n",
    "# Десcериализация строки в array\n",
    "train_ds = train_ds.map(lambda x,y: (tf.io.parse_tensor(x, out_type=tf.int64), y))\n",
    "\n",
    "for i in train_ds.take(1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5639570e",
   "metadata": {
    "papermill": {
     "duration": 0.01714,
     "end_time": "2022-08-05T11:45:03.456349",
     "exception": false,
     "start_time": "2022-08-05T11:45:03.439209",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Сохранение кодировщика в `save model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a0a958c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-05T11:45:03.487087Z",
     "iopub.status.busy": "2022-08-05T11:45:03.486638Z",
     "iopub.status.idle": "2022-08-05T11:45:04.633584Z",
     "shell.execute_reply": "2022-08-05T11:45:04.632517Z"
    },
    "papermill": {
     "duration": 1.166685,
     "end_time": "2022-08-05T11:45:04.637522",
     "exception": false,
     "start_time": "2022-08-05T11:45:03.470837",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "text_vectorization (TextVect (None, 128)               0         \n",
      "=================================================================\n",
      "Total params: 0\n",
      "Trainable params: 0\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-05 11:45:03.829237: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    }
   ],
   "source": [
    "# Создание модели из одного слоя (кодировщик)\n",
    "vectorize_layer_model = tf.keras.models.Sequential()\n",
    "vectorize_layer_model.add(tf.keras.Input(shape=(1,), dtype=tf.string))\n",
    "vectorize_layer_model.add(int_vectorize_layer)\n",
    "vectorize_layer_model.summary()\n",
    "\n",
    "# Сохранение модели\n",
    "path = str(path_models / filename_model_int_vect)\n",
    "vectorize_layer_model.save(path, save_format=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aa7a5ba6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-05T11:45:04.668708Z",
     "iopub.status.busy": "2022-08-05T11:45:04.668309Z",
     "iopub.status.idle": "2022-08-05T11:45:04.995920Z",
     "shell.execute_reply": "2022-08-05T11:45:04.994745Z"
    },
    "papermill": {
     "duration": 0.346363,
     "end_time": "2022-08-05T11:45:04.998549",
     "exception": false,
     "start_time": "2022-08-05T11:45:04.652186",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Загрузка сохранённой модели (кодировщик)\n",
    "path = str(path_models / filename_model_int_vect)\n",
    "\n",
    "loaded_vectorize_layer_model = tf.keras.models.load_model(path)\n",
    "loaded_vectorize_layer = loaded_vectorize_layer_model.layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b0accb7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-05T11:45:05.030144Z",
     "iopub.status.busy": "2022-08-05T11:45:05.029259Z",
     "iopub.status.idle": "2022-08-05T11:45:05.177040Z",
     "shell.execute_reply": "2022-08-05T11:45:05.176090Z"
    },
    "papermill": {
     "duration": 0.166096,
     "end_time": "2022-08-05T11:45:05.179451",
     "exception": false,
     "start_time": "2022-08-05T11:45:05.013355",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(54,), dtype=int64, numpy=\n",
      "array([ 5135,  1916,   423,   123,   677,    28,    16,  2550,   337,\n",
      "        2186,  1339,   351,  1044,    51,  4331,   840,  1344,   755,\n",
      "        1796,  1485,  1322,  1307,   682,  4897,   106,   463,  8694,\n",
      "         741,  2726,  1307,   768, 10628,   484,   608,  9057,  1810,\n",
      "        4918,  3608,  1792,  2550,    51,     2,    10,   275,   240,\n",
      "          30,  1073, 12241, 15162, 12587,   376,  2971,  7744,  1173])>, <tf.Tensor: shape=(), dtype=int64, numpy=0>)\n"
     ]
    }
   ],
   "source": [
    "# Проверка загруженной модели (кодировщик)\n",
    "# ⚠️ В текущей версии tf в kaggle ошибка, при загрузке не срабатывает конфиг, \n",
    "# тензор меньшего размера, отсекаются нули\n",
    "# Подаём очищенный, но ещё не закодированный набор\n",
    "path = str(path_data / filename_train_cleaned)\n",
    "\n",
    "train_ds = tf.data.TFRecordDataset(filenames = [path])\n",
    "train_ds = train_ds.map(parse_function)\n",
    "\n",
    "# Кодирование набора данных\n",
    "train_ds = encode_description(train_ds, loaded_vectorize_layer)\n",
    "\n",
    "for i in train_ds.take(1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c487efe",
   "metadata": {
    "papermill": {
     "duration": 0.014145,
     "end_time": "2022-08-05T11:45:05.208321",
     "exception": false,
     "start_time": "2022-08-05T11:45:05.194176",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 6 Балансировка классов с повторениями - `tf.data.Dataset.sample_from_datasets`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44432ff0",
   "metadata": {
    "papermill": {
     "duration": 0.013967,
     "end_time": "2022-08-05T11:45:05.236721",
     "exception": false,
     "start_time": "2022-08-05T11:45:05.222754",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "* Если набор данных сбалансированный, то обучение более плавное т.к. объекты повторяются в разных выборках, но вес их одинаковый по сравнению с `class_weight`\n",
    "* т.е. проходов больше, но график обучения более плавный из-за того, что данные размазаны.\n",
    "* если подавать в `model.fit()` из-за большого количества классов и большого количества преобразований, фильтрации, обучение будет очень долгим.\n",
    "* по этому преобразуем в готовый набор данных и сохраним в `TFRecords`.\n",
    "\n",
    "*Примечания:*\n",
    "* если подавать напрямую, то нужно указать сколько шагов в эпохе т.к. функция балансировки выдаёт бесконечное количество образцов.\n",
    "\n",
    "```python\n",
    "# Параметр нужен т.к. бесконечные повторения элементов - эпоха выбрать все элементя один раз\n",
    "steps_per_epoch = int(np.ceil(54_214 / conf.BATCH_SIZE))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dd10ce66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-05T11:45:05.269846Z",
     "iopub.status.busy": "2022-08-05T11:45:05.268551Z",
     "iopub.status.idle": "2022-08-05T11:45:05.274907Z",
     "shell.execute_reply": "2022-08-05T11:45:05.273985Z"
    },
    "papermill": {
     "duration": 0.025047,
     "end_time": "2022-08-05T11:45:05.277195",
     "exception": false,
     "start_time": "2022-08-05T11:45:05.252148",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_infinity_dataset(dataset, class_id):\n",
    "  # Фильтрует набор, набирает в буфер 10k элементов, возвращает бесконечное количество элементов.\n",
    "\n",
    "  dataset_filterd = dataset.filter(lambda x, y: y == class_id)\n",
    "  # dataset.shuffle(buffer_size=3) - создаётся буфер размера N (например = 3) в который помещаются 3 рандомных элемента, \n",
    "  # постепенно один за другим выбираются из него и заменяются теми, что не вошли в буфер\n",
    "  # чем больше тем лучше\n",
    "  dataset_filterd = dataset_filterd.shuffle(10_000)\n",
    "  # dataset.repeat(3) - сколько раз реинацилизировать полный dataset - сколько раз подавать в эпоху dataset.\n",
    "  # ⚠️ .reapeat(-1) или repeat() - бесконечное повторение\n",
    "  dataset_filterd = dataset_filterd.repeat(-1)\n",
    "  return dataset_filterd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2fbe607e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-05T11:45:05.309026Z",
     "iopub.status.busy": "2022-08-05T11:45:05.307911Z",
     "iopub.status.idle": "2022-08-05T11:45:07.741891Z",
     "shell.execute_reply": "2022-08-05T11:45:07.740381Z"
    },
    "papermill": {
     "duration": 2.452726,
     "end_time": "2022-08-05T11:45:07.744901",
     "exception": false,
     "start_time": "2022-08-05T11:45:05.292175",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество поднаборов по жанрам: 27\n",
      "(<tf.Tensor: shape=(128,), dtype=int64, numpy=\n",
      "array([    8,    10,  2647,  2190,   994,     1,     1,   105,   254,\n",
      "        2932,     1, 11313,    38,   404,   250,  8975,    39,  5148,\n",
      "         661,   522,   493,  4353,   188,     4,  1065,  1761,   635,\n",
      "          25,   920,    82,   943,  1408,   111,    20,     2,   422,\n",
      "         379,    89,  1055,   832,  1746,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0])>, <tf.Tensor: shape=(), dtype=int64, numpy=0>)\n"
     ]
    }
   ],
   "source": [
    "path = str(path_data / filename_train_clean_encoded)\n",
    "\n",
    "train_ds = tf.data.TFRecordDataset(filenames = [path])\n",
    "train_ds = train_ds.map(parse_function)\n",
    "\n",
    "# Десcериализация строки в array\n",
    "train_ds = train_ds.map(lambda x,y: (tf.io.parse_tensor(x, out_type=tf.int64), y))\n",
    "\n",
    "\n",
    "filtered_dataset = []\n",
    "for class_id in range(27):\n",
    "    filtered_dataset.append(generate_infinity_dataset(train_ds, class_id))\n",
    "\n",
    "print('Количество поднаборов по жанрам:', len(filtered_dataset))\n",
    "\n",
    "for i in filtered_dataset[0].take(1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "68403965",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-05T11:45:07.776650Z",
     "iopub.status.busy": "2022-08-05T11:45:07.775958Z",
     "iopub.status.idle": "2022-08-05T11:45:07.796806Z",
     "shell.execute_reply": "2022-08-05T11:45:07.795652Z"
    },
    "papermill": {
     "duration": 0.039964,
     "end_time": "2022-08-05T11:45:07.799782",
     "exception": false,
     "start_time": "2022-08-05T11:45:07.759818",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Балансировка набора данных\n",
    "weight_list = [1*0.037 for x in range(0,27)]\n",
    "# Формируется сбалансированный набор данных из других наборов\n",
    "train_ds_resampled = tf.data.experimental.sample_from_datasets(filtered_dataset, weights=weight_list)\n",
    "# example_ds_resampled = tf.data.Dataset.sample_from_datasets(filtered_dataset, weights=weight_list)\n",
    "\n",
    "train_ds_resampled = train_ds_resampled.prefetch(10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "323e9a2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-05T11:45:07.831631Z",
     "iopub.status.busy": "2022-08-05T11:45:07.831226Z",
     "iopub.status.idle": "2022-08-05T12:55:25.011096Z",
     "shell.execute_reply": "2022-08-05T12:55:25.008948Z"
    },
    "papermill": {
     "duration": 4217.199511,
     "end_time": "2022-08-05T12:55:25.014355",
     "exception": false,
     "start_time": "2022-08-05T11:45:07.814844",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-05 11:48:39.657830: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:175] Filling up shuffle buffer (this may take a while): 580 of 10000\n",
      "2022-08-05 11:48:39.739988: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:228] Shuffle buffer filled.\n"
     ]
    }
   ],
   "source": [
    "path = str(path_data / filename_train_clean_encode_resampled)\n",
    "\n",
    "with tf.io.TFRecordWriter(path) as writer:\n",
    "    for sample in train_ds_resampled.take(HP_DATASET['dataset_size_resampled']):    \n",
    "        label = int64_feature(sample[1])\n",
    "        # Для преобразования в скаляр, array напрямую нельзя кодировать\n",
    "        desc_serialized = tf.io.serialize_tensor(sample[0])\n",
    "        desc = bytes_feature(desc_serialized)\n",
    "        pr = create_record(desc, label)\n",
    "        writer.write(pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dbb0552c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-05T12:55:25.048587Z",
     "iopub.status.busy": "2022-08-05T12:55:25.048134Z",
     "iopub.status.idle": "2022-08-05T12:57:47.073203Z",
     "shell.execute_reply": "2022-08-05T12:57:47.071952Z"
    },
    "papermill": {
     "duration": 142.060067,
     "end_time": "2022-08-05T12:57:47.090759",
     "exception": false,
     "start_time": "2022-08-05T12:55:25.030692",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Набор объёмом: 500000\n",
      "(<tf.Tensor: shape=(128,), dtype=int64, numpy=\n",
      "array([12493,   146,  1056, 15844,  5633,    17,   600,   218,  1899,\n",
      "        1905,   540,   498, 12493,  1140,  1453,   180, 30678,  2295,\n",
      "       12658,     1, 12649, 12983,  2440,     1,  2960,     1,    67,\n",
      "        9043, 48673,   702,     1,  3143, 23009,  7891, 10238,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0])>, <tf.Tensor: shape=(), dtype=int64, numpy=16>)\n"
     ]
    }
   ],
   "source": [
    "# Проверка записанных данных\n",
    "path = str(path_data / filename_train_clean_encode_resampled)\n",
    "train_ds_resampled = tf.data.TFRecordDataset(filenames = [path])\n",
    "train_ds_resampled = train_ds_resampled.map(parse_function)\n",
    "train_ds_resampled = train_ds_resampled.map(lambda x,y: (tf.io.parse_tensor(x, out_type=tf.int64), y))\n",
    "\n",
    "len_tfr = []\n",
    "for i in train_ds_resampled:\n",
    "    len_tfr.append(i)\n",
    "print('Набор объёмом:', len(len_tfr))\n",
    "\n",
    "for i in train_ds_resampled.take(1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98aa26df",
   "metadata": {
    "papermill": {
     "duration": 0.014797,
     "end_time": "2022-08-05T12:57:47.120617",
     "exception": false,
     "start_time": "2022-08-05T12:57:47.105820",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 7 Балансировка классов `class_weight`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46b29b9",
   "metadata": {
    "papermill": {
     "duration": 0.014989,
     "end_time": "2022-08-05T12:57:47.150588",
     "exception": false,
     "start_time": "2022-08-05T12:57:47.135599",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Жанры не сбалансированы в наборе данных. Вместо балансировки `dataset`, можно задавать \"важность(вес)\" `class_weight` для классов. Меньше объектов какого-либо класса, важность **класса** выше.\n",
    "\n",
    "* ❗`class_weight` - Optional dictionary mapping class indices (integers) to a weight (float) value, used for weighting the loss function (during training only). This can be useful to tell the model to **\"pay more attention\" to samples from an under-represented class**. \n",
    "* ⚠️Параметр задаётся в `model.fit()`.\n",
    "\n",
    "\n",
    "Также есть другой параметр: `Sample weights` - увеличивает роль отдельного объекта (наблюдения).\n",
    "\n",
    "* ❗`Sample weights` are used to increase the importance of a single data-point (let's say, some of your data is more trustworthy, then they receive a higher weight).\n",
    "\n",
    "So: `The sample weights` exist to change the importance of data-points whereas the `class weights` change the weights to correct class imbalance.\n",
    "\n",
    "[Дополнительная информация - Quora](https://www.quora.com/What-is-the-difference-between-class_weight-and-sample_weight-in-keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1a141964",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-05T12:57:47.182525Z",
     "iopub.status.busy": "2022-08-05T12:57:47.182122Z",
     "iopub.status.idle": "2022-08-05T12:57:47.191477Z",
     "shell.execute_reply": "2022-08-05T12:57:47.190268Z"
    },
    "papermill": {
     "duration": 0.028319,
     "end_time": "2022-08-05T12:57:47.193950",
     "exception": false,
     "start_time": "2022-08-05T12:57:47.165631",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_class_weight(dataset):\n",
    "  # Расчёт весов для class_weight\n",
    "  class_list = []\n",
    "  for i in dataset:\n",
    "      class_list.append(i[1].numpy())\n",
    "\n",
    "  amount = len(class_list)\n",
    "  print(f'Всего записей: {amount}')\n",
    "\n",
    "  unique_class = set(class_list)\n",
    "\n",
    "  class_pct = {}\n",
    "\n",
    "  for i in unique_class:\n",
    "      class_pct[i] = round(class_list.count(i) / amount, 7)\n",
    "\n",
    "  labels_unique = list(set(class_list))\n",
    "\n",
    "  class_weight_ = class_weight.compute_class_weight(\n",
    "                  class_weight = 'balanced',\n",
    "                  classes = labels_unique, \n",
    "                  y = np.array(class_list))\n",
    "\n",
    "  weighted_class = {}\n",
    "\n",
    "  for class_name, weight in zip(unique_class, class_weight_):\n",
    "      weighted_class[class_name] = weight\n",
    "\n",
    "  return weighted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6ad8b0e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-05T12:57:47.226418Z",
     "iopub.status.busy": "2022-08-05T12:57:47.226004Z",
     "iopub.status.idle": "2022-08-05T12:59:23.466949Z",
     "shell.execute_reply": "2022-08-05T12:59:23.465436Z"
    },
    "papermill": {
     "duration": 96.263152,
     "end_time": "2022-08-05T12:59:23.472457",
     "exception": false,
     "start_time": "2022-08-05T12:57:47.209305",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего записей: 500000\n",
      "Балансировка классов - 1.0000488753825723\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 1.0096787807926786,\n",
       " 1: 0.9939626707379378,\n",
       " 2: 1.003061343219506,\n",
       " 3: 1.003224363103013,\n",
       " 4: 1.0079750989831546,\n",
       " 5: 0.9992186110461619,\n",
       " 6: 0.9938559823173143,\n",
       " 7: 1.0073719479148409,\n",
       " 8: 0.9943362606592847,\n",
       " 9: 0.9980876640357076,\n",
       " 10: 1.0076460179844662,\n",
       " 11: 1.0078105316200554,\n",
       " 12: 1.0003521239476296,\n",
       " 13: 0.9955657501488371,\n",
       " 14: 1.0042580541495942,\n",
       " 15: 0.9935893614399892,\n",
       " 16: 0.9937493167973447,\n",
       " 17: 1.0074267500010075,\n",
       " 18: 0.992311569955981,\n",
       " 19: 0.9846609516945031,\n",
       " 20: 0.9993264539700242,\n",
       " 21: 0.9970129492041843,\n",
       " 22: 0.9969592742136484,\n",
       " 23: 1.0175010175010175,\n",
       " 24: 0.9923647456469921,\n",
       " 25: 1.0022470378588797,\n",
       " 26: 0.9977650063856961}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Как сбалансированы классы в сгенерированном dataset, который подаётся в fit()\n",
    "# Проверка записанных данных\n",
    "path = str(path_data / filename_train_clean_encode_resampled)\n",
    "train_ds_resampled = tf.data.TFRecordDataset(filenames = [path])\n",
    "train_ds_resampled = train_ds_resampled.map(parse_function)\n",
    "train_ds_resampled = train_ds_resampled.map(lambda x,y: (tf.io.parse_tensor(x, out_type=tf.int64), y))\n",
    "\n",
    "\n",
    "weighted_class = calc_class_weight(train_ds_resampled)\n",
    "\n",
    "avg = np.mean(list(weighted_class.values()))\n",
    "\n",
    "print(f'Балансировка классов - {avg}')\n",
    "\n",
    "weighted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e27d0ad3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-05T12:59:23.509045Z",
     "iopub.status.busy": "2022-08-05T12:59:23.508603Z",
     "iopub.status.idle": "2022-08-05T12:59:34.117797Z",
     "shell.execute_reply": "2022-08-05T12:59:34.116094Z"
    },
    "papermill": {
     "duration": 10.629079,
     "end_time": "2022-08-05T12:59:34.120552",
     "exception": false,
     "start_time": "2022-08-05T12:59:23.491473",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего записей: 54214\n",
      "Балансировка классов - 4.308273963785575\n",
      "{0: 0.1475006189617223, 1: 1.2620527504248436, 2: 3.403264281230383, 3: 0.15332360460643907, 4: 0.26962883388289594, 5: 3.976090942427576, 6: 2.271409418468242, 7: 0.9110371714727432, 8: 4.647976680384088, 9: 4.031979770935594, 10: 1.5269398676242782, 11: 6.216488934755189, 12: 0.3958064115761731, 13: 3.103440380101895, 14: 2.74682069210113, 15: 2.590872162485066, 16: 5.135360424362982, 17: 1.945664656904967, 18: 2.561130007558579, 19: 6.294438639266225, 20: 8.263069654016157, 21: 11.093513402905668, 22: 7.577078965758211, 23: 2.987985008818342, 24: 10.350133638793432, 25: 7.248830057494318, 26: 15.211560044893378}\n"
     ]
    }
   ],
   "source": [
    "# Как сбалансированы классы в начальном наборе данных\n",
    "path = str(path_data / filename_train_clean_encoded)\n",
    "train_ds = tf.data.TFRecordDataset(filenames = [path])\n",
    "train_ds = train_ds.map(parse_function)\n",
    "train_ds = train_ds.map(lambda x,y: (tf.io.parse_tensor(x, out_type=tf.int64), y))\n",
    "\n",
    "\n",
    "weighted_class = calc_class_weight(train_ds)\n",
    "\n",
    "avg = np.mean(list(weighted_class.values()))\n",
    "\n",
    "print(f'Балансировка классов - {avg}')\n",
    "print(weighted_class)\n",
    "\n",
    "weights = {}\n",
    "for key, value in weighted_class.items():\n",
    "    weights[key] = round(value, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7c410145",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-05T12:59:34.155202Z",
     "iopub.status.busy": "2022-08-05T12:59:34.154102Z",
     "iopub.status.idle": "2022-08-05T12:59:34.160891Z",
     "shell.execute_reply": "2022-08-05T12:59:34.160046Z"
    },
    "papermill": {
     "duration": 0.026106,
     "end_time": "2022-08-05T12:59:34.163006",
     "exception": false,
     "start_time": "2022-08-05T12:59:34.136900",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "weights = {0: 0.1475, 1: 1.2621, 2: 3.4033, 3: 0.1533, 4: 0.2696, 5: 3.9761,\n",
    "           6: 2.2714, 7: 0.911, 8: 4.648, 9: 4.032, 10: 1.5269, 11: 6.2165, \n",
    "           12: 0.3958, 13: 3.1034, 14: 2.7468, 15: 2.5909, 16: 5.1354, 17: 1.9457,\n",
    "           18: 2.5611, 19: 6.2944, 20: 8.2631, 21: 11.0935, 22: 7.5771, 23: 2.988,\n",
    "           24: 10.3501, 25: 7.2488, 26: 15.2116}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e984f8a0",
   "metadata": {
    "papermill": {
     "duration": 0.016142,
     "end_time": "2022-08-05T12:59:34.195299",
     "exception": false,
     "start_time": "2022-08-05T12:59:34.179157",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 8 Кодирование тестового набора данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bfce04",
   "metadata": {
    "papermill": {
     "duration": 0.015551,
     "end_time": "2022-08-05T12:59:34.226794",
     "exception": false,
     "start_time": "2022-08-05T12:59:34.211243",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Загрузка и очистка данных -> `test_cleaned.tfrecords`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4030bf9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-05T12:59:34.261167Z",
     "iopub.status.busy": "2022-08-05T12:59:34.260291Z",
     "iopub.status.idle": "2022-08-05T13:01:37.567324Z",
     "shell.execute_reply": "2022-08-05T13:01:37.566190Z"
    },
    "papermill": {
     "duration": 123.327721,
     "end_time": "2022-08-05T13:01:37.570547",
     "exception": false,
     "start_time": "2022-08-05T12:59:34.242826",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Загрузка и разделение на описание и лейблы\n",
    "path_test_data = '../input/genre-classification-dataset-imdb/Genre Classification Dataset/test_data_solution.txt'\n",
    "\n",
    "test_ds = load_data(path_test_data)\n",
    "test_ds = test_ds.map(encode_label)\n",
    "\n",
    "# Очистка данных от лишнего\n",
    "test_ds = test_ds.map(lambda *x: clean_data(x, stopwords_eng))\n",
    "\n",
    "# Сохранение очищенного набора\n",
    "path = str(path_data / filename_test_cleaned)\n",
    "\n",
    "with tf.io.TFRecordWriter(path) as writer:\n",
    "  for sample in test_ds:\n",
    "      label = int64_feature(sample[1])\n",
    "      desc = bytes_feature(sample[0])\n",
    "      pr = create_record(desc, label)\n",
    "      writer.write(pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "221bcb70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-05T13:01:37.604012Z",
     "iopub.status.busy": "2022-08-05T13:01:37.603265Z",
     "iopub.status.idle": "2022-08-05T13:01:37.905029Z",
     "shell.execute_reply": "2022-08-05T13:01:37.903581Z"
    },
    "papermill": {
     "duration": 0.322031,
     "end_time": "2022-08-05T13:01:37.908387",
     "exception": false,
     "start_time": "2022-08-05T13:01:37.586356",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'lr brane loves life car apartment job especially girlfriend vespa one day showering vespa runs shampoo lr runs across street convenience store buy quick trip minutes returns vespa gone every trace existence wiped lrs life becomes tortured existence one strange event another occurs confirm mind conspiracy working finding vespa'>, <tf.Tensor: shape=(), dtype=int64, numpy=1>)\n"
     ]
    }
   ],
   "source": [
    "for i in test_ds.take(1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80983af1",
   "metadata": {
    "papermill": {
     "duration": 0.015136,
     "end_time": "2022-08-05T13:01:37.940272",
     "exception": false,
     "start_time": "2022-08-05T13:01:37.925136",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Кодирование набора данных -> `test_clean_encoded.tfrecords`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7ad4d92a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-05T13:01:37.973018Z",
     "iopub.status.busy": "2022-08-05T13:01:37.972571Z",
     "iopub.status.idle": "2022-08-05T13:01:38.072065Z",
     "shell.execute_reply": "2022-08-05T13:01:38.070738Z"
    },
    "papermill": {
     "duration": 0.119436,
     "end_time": "2022-08-05T13:01:38.075017",
     "exception": false,
     "start_time": "2022-08-05T13:01:37.955581",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = str(path_data / filename_test_cleaned)\n",
    "test_ds = tf.data.TFRecordDataset(filenames = [path])\n",
    "test_ds = test_ds.map(parse_function)\n",
    "\n",
    "# Кодирование тестового набора\n",
    "# ⚠️не проверял, можно ли кодировать загруженным слоем (теряет нули)\n",
    "test_ds_clean_encoded = encode_description(test_ds, int_vectorize_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a02809ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-05T13:01:38.108944Z",
     "iopub.status.busy": "2022-08-05T13:01:38.108499Z",
     "iopub.status.idle": "2022-08-05T13:02:17.134249Z",
     "shell.execute_reply": "2022-08-05T13:02:17.133239Z"
    },
    "papermill": {
     "duration": 39.045425,
     "end_time": "2022-08-05T13:02:17.136847",
     "exception": false,
     "start_time": "2022-08-05T13:01:38.091422",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Сохранение на диск\n",
    "path = str(path_data / filename_test_clean_encoded)\n",
    "\n",
    "with tf.io.TFRecordWriter(path) as writer:\n",
    "    for sample in test_ds_clean_encoded:\n",
    "        label = int64_feature(sample[1])\n",
    "        # Для преобразования в скаляр, array напрямую нельзя кодировать\n",
    "        desc_serialized = tf.io.serialize_tensor(sample[0])\n",
    "        desc = bytes_feature(desc_serialized)\n",
    "        pr = create_record(desc, label)\n",
    "        writer.write(pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5412b26a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-05T13:02:17.170514Z",
     "iopub.status.busy": "2022-08-05T13:02:17.169880Z",
     "iopub.status.idle": "2022-08-05T13:02:17.231028Z",
     "shell.execute_reply": "2022-08-05T13:02:17.229520Z"
    },
    "papermill": {
     "duration": 0.081057,
     "end_time": "2022-08-05T13:02:17.233592",
     "exception": false,
     "start_time": "2022-08-05T13:02:17.152535",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(128,), dtype=int64, numpy=\n",
      "array([38379,     1,   546,     2,   223,   561,   109,   782,   262,\n",
      "       24791,     3,    20, 26998, 24791,   480, 27019, 38379,   480,\n",
      "         204,   304,  7051,  1009,  1127,  2099,   296,  1324,   236,\n",
      "       24791,   867,   111,  3499,   803,  8292,     1,     2,    72,\n",
      "        3326,   803,     3,   380,   576,    99,  4446, 12863,   370,\n",
      "        2684,   149,   588, 24791,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0])>, <tf.Tensor: shape=(), dtype=int64, numpy=1>)\n"
     ]
    }
   ],
   "source": [
    "# Проверка \n",
    "path = str(path_data / filename_test_clean_encoded)\n",
    "\n",
    "test_ds = tf.data.TFRecordDataset(filenames = [path])\n",
    "test_ds = test_ds.map(parse_function)\n",
    "test_ds = test_ds.map(lambda x,y: (tf.io.parse_tensor(x, out_type=tf.int64), y))\n",
    "\n",
    "for i in test_ds.take(1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4a91bab4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-05T13:02:17.266695Z",
     "iopub.status.busy": "2022-08-05T13:02:17.266274Z",
     "iopub.status.idle": "2022-08-05T13:02:18.502326Z",
     "shell.execute_reply": "2022-08-05T13:02:18.501026Z"
    },
    "papermill": {
     "duration": 1.256371,
     "end_time": "2022-08-05T13:02:18.505600",
     "exception": false,
     "start_time": "2022-08-05T13:02:17.249229",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 104\r\n",
      "drwxr-xr-x 4 root root  4096 Aug  5 11:41 .\r\n",
      "drwxr-xr-x 6 root root  4096 Aug  5 11:41 ..\r\n",
      "---------- 1 root root 89547 Aug  5 13:02 __notebook__.ipynb\r\n",
      "drwxr-xr-x 2 root root  4096 Aug  5 13:01 data\r\n",
      "drwxr-xr-x 3 root root  4096 Aug  5 11:45 models\r\n"
     ]
    }
   ],
   "source": [
    "!ls -all /kaggle/working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "45433a76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-05T13:02:18.539520Z",
     "iopub.status.busy": "2022-08-05T13:02:18.539094Z",
     "iopub.status.idle": "2022-08-05T13:02:19.732004Z",
     "shell.execute_reply": "2022-08-05T13:02:19.730714Z"
    },
    "papermill": {
     "duration": 1.213398,
     "end_time": "2022-08-05T13:02:19.735012",
     "exception": false,
     "start_time": "2022-08-05T13:02:18.521614",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 701528\r\n",
      "drwxr-xr-x 2 root root      4096 Aug  5 13:01 .\r\n",
      "drwxr-xr-x 4 root root      4096 Aug  5 11:41 ..\r\n",
      "-rw-r--r-- 1 root root  59403200 Aug  5 13:02 test_clean_encoded.tfrecords\r\n",
      "-rw-r--r-- 1 root root  25756938 Aug  5 13:01 test_cleaned.tfrecords\r\n",
      "-rw-r--r-- 1 root root 548000000 Aug  5 12:55 train_clean_encode_resampled.tfrecords\r\n",
      "-rw-r--r-- 1 root root  59418544 Aug  5 11:45 train_clean_encoded.tfrecords\r\n",
      "-rw-r--r-- 1 root root  25763511 Aug  5 11:43 train_cleaned.tfrecords\r\n"
     ]
    }
   ],
   "source": [
    "!ls -all /kaggle/working/data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00312162",
   "metadata": {
    "papermill": {
     "duration": 0.015377,
     "end_time": "2022-08-05T13:02:19.766511",
     "exception": false,
     "start_time": "2022-08-05T13:02:19.751134",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 9 Архивирование подготовленных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d2fe1b26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-05T13:02:19.800287Z",
     "iopub.status.busy": "2022-08-05T13:02:19.799873Z",
     "iopub.status.idle": "2022-08-05T13:02:19.804874Z",
     "shell.execute_reply": "2022-08-05T13:02:19.803680Z"
    },
    "papermill": {
     "duration": 0.025231,
     "end_time": "2022-08-05T13:02:19.807438",
     "exception": false,
     "start_time": "2022-08-05T13:02:19.782207",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# shutil.make_archive(base_name='data', format='zip', base_dir='/kaggle/working/data')\n",
    "# shutil.make_archive(base_name='models', format='zip', base_dir='/kaggle/working/models')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('tf29')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4871.500165,
   "end_time": "2022-08-05T13:02:22.554270",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-08-05T11:41:11.054105",
   "version": "2.3.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "1cd0279c901e39233680c9aeb5bd47125a00ab4a8fa8904d2f5d220cbd486de0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
