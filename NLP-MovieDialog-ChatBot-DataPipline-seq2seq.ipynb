{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2c70b79",
   "metadata": {
    "papermill": {
     "duration": 0.01096,
     "end_time": "2022-08-11T20:47:03.055986",
     "exception": false,
     "start_time": "2022-08-11T20:47:03.045026",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Обучение чат-бота на основе диалогов из фильмов\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e446f9dc",
   "metadata": {
    "papermill": {
     "duration": 0.009117,
     "end_time": "2022-08-11T20:47:03.075087",
     "exception": false,
     "start_time": "2022-08-11T20:47:03.065970",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1 Импорт библиотек, установка, настройка"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09255135",
   "metadata": {
    "papermill": {
     "duration": 0.00943,
     "end_time": "2022-08-11T20:47:03.094117",
     "exception": false,
     "start_time": "2022-08-11T20:47:03.084687",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1.1 Импорт"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a458ca9c",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-08-11T20:47:03.116231Z",
     "iopub.status.busy": "2022-08-11T20:47:03.114894Z",
     "iopub.status.idle": "2022-08-11T20:47:08.259135Z",
     "shell.execute_reply": "2022-08-11T20:47:08.258000Z"
    },
    "papermill": {
     "duration": 5.158097,
     "end_time": "2022-08-11T20:47:08.261695",
     "exception": false,
     "start_time": "2022-08-11T20:47:03.103598",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.4'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import codecs\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395b176d",
   "metadata": {
    "papermill": {
     "duration": 0.010432,
     "end_time": "2022-08-11T20:47:08.282307",
     "exception": false,
     "start_time": "2022-08-11T20:47:08.271875",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1.3 Гиперпараметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e25cd1e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T20:47:08.305058Z",
     "iopub.status.busy": "2022-08-11T20:47:08.303711Z",
     "iopub.status.idle": "2022-08-11T20:47:08.309466Z",
     "shell.execute_reply": "2022-08-11T20:47:08.308378Z"
    },
    "papermill": {
     "duration": 0.019236,
     "end_time": "2022-08-11T20:47:08.311571",
     "exception": false,
     "start_time": "2022-08-11T20:47:08.292335",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "HP_DATASET = {'seq_len'                : 100,\n",
    "              'batch_size'             : 1024,  # 64\n",
    "              'examples_per_epoch'     : None,\n",
    "              'vocab_size'             : None,\n",
    "             }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e998ff",
   "metadata": {
    "papermill": {
     "duration": 0.009506,
     "end_time": "2022-08-11T20:47:08.330832",
     "exception": false,
     "start_time": "2022-08-11T20:47:08.321326",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1.4 Пути и операции с файлами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5c1c3e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T20:47:08.352752Z",
     "iopub.status.busy": "2022-08-11T20:47:08.351530Z",
     "iopub.status.idle": "2022-08-11T20:47:08.361039Z",
     "shell.execute_reply": "2022-08-11T20:47:08.359796Z"
    },
    "papermill": {
     "duration": 0.023487,
     "end_time": "2022-08-11T20:47:08.364037",
     "exception": false,
     "start_time": "2022-08-11T20:47:08.340550",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder data was created.\n",
      "Folder models was created.\n",
      "Folder models/BackupAndRestore was created.\n",
      "Folder models/Checkpoint was created.\n",
      "Folder mlruns was created.\n",
      "Folder tblogs was created.\n",
      "Folder img was created.\n"
     ]
    }
   ],
   "source": [
    "path_dataset_folder = Path('../input/movie-dialog-corpus/')\n",
    "\n",
    "path_data = Path('./data/')\n",
    "\n",
    "path_models = Path('./models/')\n",
    "path_backup = Path('./models/BackupAndRestore/')\n",
    "path_chekpoint = Path('./models/Checkpoint/')\n",
    "\n",
    "path_mlflow = Path('./mlruns/')\n",
    "path_tblogs = Path('./tblogs/')\n",
    "path_img = Path('./img/')\n",
    "\n",
    "\n",
    "paths = [path_data, path_models, path_backup, path_chekpoint, path_mlflow, path_tblogs, path_img]\n",
    "\n",
    "for path in paths:\n",
    "    if os.path.exists(path):\n",
    "        print(f\"Folder {path} exists!\")\n",
    "    else:\n",
    "        os.makedirs(path)\n",
    "        print(f\"Folder {path} was created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f3ec90c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T20:47:08.386558Z",
     "iopub.status.busy": "2022-08-11T20:47:08.386144Z",
     "iopub.status.idle": "2022-08-11T20:47:08.391434Z",
     "shell.execute_reply": "2022-08-11T20:47:08.390335Z"
    },
    "papermill": {
     "duration": 0.018607,
     "end_time": "2022-08-11T20:47:08.393448",
     "exception": false,
     "start_time": "2022-08-11T20:47:08.374841",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "filename_conversations = 'movie_conversations.tsv' \n",
    "filename_lines = 'movie_lines.tsv' \n",
    "\n",
    "filename_model_ids_from_chars = 'ids_from_chars'\n",
    "filename_model_chars_from_ids = 'chars_from_ids'\n",
    "\n",
    "\n",
    "filename_input_target_ids = f\"input_target_ids_len60.tfrecords\"\n",
    "filename_input_target_ids = f\"input_target_ids_len200.tfrecords\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97bd9d5",
   "metadata": {
    "papermill": {
     "duration": 0.009739,
     "end_time": "2022-08-11T20:47:08.413099",
     "exception": false,
     "start_time": "2022-08-11T20:47:08.403360",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2 Подготовка текста к загрузке в Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1aea2a",
   "metadata": {
    "papermill": {
     "duration": 0.009681,
     "end_time": "2022-08-11T20:47:08.432711",
     "exception": false,
     "start_time": "2022-08-11T20:47:08.423030",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2.1 Фразы - `movie_lines.tsv`\n",
    "* id фразы - `L194`\n",
    "* id персонажа - `u0`\n",
    "* id фильма - `m0`\n",
    "* фраза `text`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1016663",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T20:47:08.454689Z",
     "iopub.status.busy": "2022-08-11T20:47:08.454268Z",
     "iopub.status.idle": "2022-08-11T20:47:08.459365Z",
     "shell.execute_reply": "2022-08-11T20:47:08.458199Z"
    },
    "papermill": {
     "duration": 0.018754,
     "end_time": "2022-08-11T20:47:08.461443",
     "exception": false,
     "start_time": "2022-08-11T20:47:08.442689",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_tab_df(x):\n",
    "    try:\n",
    "        return x.replace('\\t', ' ')\n",
    "    except:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa7d78e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T20:47:08.484002Z",
     "iopub.status.busy": "2022-08-11T20:47:08.483556Z",
     "iopub.status.idle": "2022-08-11T20:47:11.425626Z",
     "shell.execute_reply": "2022-08-11T20:47:11.424735Z"
    },
    "papermill": {
     "duration": 2.956258,
     "end_time": "2022-08-11T20:47:11.427996",
     "exception": false,
     "start_time": "2022-08-11T20:47:08.471738",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frase_id</th>\n",
       "      <th>frase_txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L1045</td>\n",
       "      <td>They do not!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L1044</td>\n",
       "      <td>They do to!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L985</td>\n",
       "      <td>I hope so.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L984</td>\n",
       "      <td>She okay?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L925</td>\n",
       "      <td>Let's go.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  frase_id     frase_txt\n",
       "0    L1045  They do not!\n",
       "1    L1044   They do to!\n",
       "2     L985    I hope so.\n",
       "3     L984     She okay?\n",
       "4     L925     Let's go."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = path_dataset_folder / filename_lines\n",
    "\n",
    "line_list = []\n",
    "with open(path, 'r', encoding='utf-8', errors=\"ignore\", newline='\\n') as text:\n",
    "    lines = text.read()\n",
    "    # в некоторых диалогах используется данный код (новая линия - u'\\x85'), он расположен внутри предложений.\n",
    "    # возможно, часть текстов были в cp1252 в них данный код означает отточие \"...\"\n",
    "    replace_list = [u'\\x85', u'\\x85', u'\\x82', u'\\x8a', u'\\x8c', u'\\x91', \n",
    "                    u'\\x92', u'\\x93', u'\\x94', u'\\x96', u'\\x97', u'\\xad']\n",
    "    \n",
    "    for char in replace_list:\n",
    "        lines = lines.replace(char, '')\n",
    "    \n",
    "    lines = lines.splitlines()\n",
    "    for line in lines:\n",
    "#         часть строчек содержит кавычки в начале и конце (kaggle)\n",
    "        line = line.lstrip('\"').rstrip('\"')\n",
    "        line = line.split('\\t', maxsplit=4)\n",
    "        line_list.append(line)\n",
    "\n",
    "df_frase = pd.DataFrame(line_list, columns=['frase_id', 'char_id', 'movie_id', 'char_name', 'frase_txt'])\n",
    "df_frase['frase_txt'] = df_frase['frase_txt'].map(clean_tab_df)\n",
    "\n",
    "df_frase = df_frase.drop(columns=['char_id','movie_id','char_name'])\n",
    "\n",
    "df_frase.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dded739",
   "metadata": {
    "papermill": {
     "duration": 0.009844,
     "end_time": "2022-08-11T20:47:11.448115",
     "exception": false,
     "start_time": "2022-08-11T20:47:11.438271",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2.2 Диалоги - `movie_conversations.tsv`\n",
    "* id первого участника в диалоге - `u0`\n",
    "* id второго участника в диалоге - `u1`\n",
    "* id фильма - `m0`\n",
    "* Фразы из диалога в хранологическом порядке - `[L194, L195, L196, L197]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6204f509",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T20:47:11.470399Z",
     "iopub.status.busy": "2022-08-11T20:47:11.469665Z",
     "iopub.status.idle": "2022-08-11T20:47:11.474885Z",
     "shell.execute_reply": "2022-08-11T20:47:11.474031Z"
    },
    "papermill": {
     "duration": 0.018555,
     "end_time": "2022-08-11T20:47:11.476764",
     "exception": false,
     "start_time": "2022-08-11T20:47:11.458209",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dealog_split(x):\n",
    "    x = x[1:]\n",
    "    x = x[:-1]\n",
    "    x = x.replace(\"'\", \"\")\n",
    "    x = x.split(' ')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a9be917",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T20:47:11.499133Z",
     "iopub.status.busy": "2022-08-11T20:47:11.498547Z",
     "iopub.status.idle": "2022-08-11T20:47:12.071420Z",
     "shell.execute_reply": "2022-08-11T20:47:12.070163Z"
    },
    "papermill": {
     "duration": 0.587067,
     "end_time": "2022-08-11T20:47:12.073820",
     "exception": false,
     "start_time": "2022-08-11T20:47:11.486753",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>char_id1</th>\n",
       "      <th>char_id2</th>\n",
       "      <th>movie_id2</th>\n",
       "      <th>frase_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>[L194, L195, L196, L197]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>[L198, L199]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>[L200, L201, L202, L203]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>[L204, L205, L206]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>[L207, L208]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  char_id1 char_id2 movie_id2                 frase_ids\n",
       "0       u0       u2        m0  [L194, L195, L196, L197]\n",
       "1       u0       u2        m0              [L198, L199]\n",
       "2       u0       u2        m0  [L200, L201, L202, L203]\n",
       "3       u0       u2        m0        [L204, L205, L206]\n",
       "4       u0       u2        m0              [L207, L208]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = path_dataset_folder / filename_conversations\n",
    "\n",
    "dialog_list = []\n",
    "with open(path, 'r', encoding='utf8') as text:\n",
    "    dialogs = text.read().splitlines()\n",
    "    for dialog in dialogs:\n",
    "        dialog = dialog.split('\\t',)\n",
    "        dialog_list.append(dialog)\n",
    "        \n",
    "df_dailogs = pd.DataFrame(dialog_list, columns=['char_id1', 'char_id2', 'movie_id2', 'frase_ids'])\n",
    "df_dailogs['frase_ids'] = df_dailogs['frase_ids'].map(dealog_split)\n",
    "df_dailogs.tail()\n",
    "df_dailogs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f760ee4",
   "metadata": {
    "papermill": {
     "duration": 0.009686,
     "end_time": "2022-08-11T20:47:12.093722",
     "exception": false,
     "start_time": "2022-08-11T20:47:12.084036",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2.3 Образцы для обучения: `input_texts` и `target_texts`\n",
    "* Что говорит персонаж `input_texts`\n",
    "* Что ему отвечают`target_texts`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "156f7efd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T20:47:12.115668Z",
     "iopub.status.busy": "2022-08-11T20:47:12.114693Z",
     "iopub.status.idle": "2022-08-11T20:47:12.604823Z",
     "shell.execute_reply": "2022-08-11T20:47:12.603685Z"
    },
    "papermill": {
     "duration": 0.5038,
     "end_time": "2022-08-11T20:47:12.607369",
     "exception": false,
     "start_time": "2022-08-11T20:47:12.103569",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_texts</th>\n",
       "      <th>target_texts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L194</td>\n",
       "      <td>L195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L195</td>\n",
       "      <td>L196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L196</td>\n",
       "      <td>L197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L198</td>\n",
       "      <td>L199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L200</td>\n",
       "      <td>L201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  input_texts target_texts\n",
       "0        L194         L195\n",
       "1        L195         L196\n",
       "2        L196         L197\n",
       "3        L198         L199\n",
       "4        L200         L201"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Составляем пары фраз\n",
    "text_pairs = []\n",
    "\n",
    "for dialog in df_dailogs['frase_ids']:\n",
    "    cell_len = len(dialog)\n",
    "    j, i = 0, 2\n",
    "    while i <= cell_len:\n",
    "        text_pairs.append(dialog[j:i])\n",
    "        i += 1\n",
    "        j += 1\n",
    "\n",
    "df_pairs = pd.DataFrame(text_pairs, columns=['input_texts', 'target_texts',])\n",
    "df_pairs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50009988",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T20:47:12.629981Z",
     "iopub.status.busy": "2022-08-11T20:47:12.629553Z",
     "iopub.status.idle": "2022-08-11T20:47:12.635810Z",
     "shell.execute_reply": "2022-08-11T20:47:12.634593Z"
    },
    "papermill": {
     "duration": 0.02017,
     "end_time": "2022-08-11T20:47:12.637935",
     "exception": false,
     "start_time": "2022-08-11T20:47:12.617765",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def string_split(x, tags=False):\n",
    "    # функция для разделения строки на элементы\n",
    "    # в начале и конце добавляет теги\n",
    "    if tags:\n",
    "        splited_string = ['<START>']\n",
    "        splited_string.extend([*x])\n",
    "        splited_string.extend(['<END>'])\n",
    "        return splited_string\n",
    "        \n",
    "    return [*x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "346e0f37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T20:47:12.660178Z",
     "iopub.status.busy": "2022-08-11T20:47:12.659765Z",
     "iopub.status.idle": "2022-08-11T20:47:14.835467Z",
     "shell.execute_reply": "2022-08-11T20:47:14.834426Z"
    },
    "papermill": {
     "duration": 2.189461,
     "end_time": "2022-08-11T20:47:14.837647",
     "exception": false,
     "start_time": "2022-08-11T20:47:12.648186",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_txt</th>\n",
       "      <th>target_txt</th>\n",
       "      <th>input_txt_split</th>\n",
       "      <th>target_txt_split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Can we make this quick?  Roxanne Korrine and A...</td>\n",
       "      <td>Well I thought we'd start with pronunciation i...</td>\n",
       "      <td>[C, a, n,  , w, e,  , m, a, k, e,  , t, h, i, ...</td>\n",
       "      <td>[&lt;START&gt;, W, e, l, l,  , I,  , t, h, o, u, g, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Well I thought we'd start with pronunciation i...</td>\n",
       "      <td>Not the hacking and gagging and spitting part....</td>\n",
       "      <td>[W, e, l, l,  , I,  , t, h, o, u, g, h, t,  , ...</td>\n",
       "      <td>[&lt;START&gt;, N, o, t,  , t, h, e,  , h, a, c, k, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not the hacking and gagging and spitting part....</td>\n",
       "      <td>Okay... then how 'bout we try out some French ...</td>\n",
       "      <td>[N, o, t,  , t, h, e,  , h, a, c, k, i, n, g, ...</td>\n",
       "      <td>[&lt;START&gt;, O, k, a, y, ., ., .,  , t, h, e, n, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           input_txt  \\\n",
       "0  Can we make this quick?  Roxanne Korrine and A...   \n",
       "1  Well I thought we'd start with pronunciation i...   \n",
       "2  Not the hacking and gagging and spitting part....   \n",
       "\n",
       "                                          target_txt  \\\n",
       "0  Well I thought we'd start with pronunciation i...   \n",
       "1  Not the hacking and gagging and spitting part....   \n",
       "2  Okay... then how 'bout we try out some French ...   \n",
       "\n",
       "                                     input_txt_split  \\\n",
       "0  [C, a, n,  , w, e,  , m, a, k, e,  , t, h, i, ...   \n",
       "1  [W, e, l, l,  , I,  , t, h, o, u, g, h, t,  , ...   \n",
       "2  [N, o, t,  , t, h, e,  , h, a, c, k, i, n, g, ...   \n",
       "\n",
       "                                    target_txt_split  \n",
       "0  [<START>, W, e, l, l,  , I,  , t, h, o, u, g, ...  \n",
       "1  [<START>, N, o, t,  , t, h, e,  , h, a, c, k, ...  \n",
       "2  [<START>, O, k, a, y, ., ., .,  , t, h, e, n, ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# id -> text - lookup\n",
    "df_input = df_pairs.merge(right = df_frase, \n",
    "                          left_on='input_texts',\n",
    "                          right_on='frase_id',\n",
    "                          how='left')\n",
    "\n",
    "input_target = df_input.merge(right = df_frase, \n",
    "                           left_on='target_texts',\n",
    "                           right_on='frase_id',\n",
    "                           how='left')\n",
    "\n",
    "input_target = input_target.drop(columns=['input_texts', 'target_texts', 'frase_id_x', 'frase_id_y'])\n",
    "input_target = input_target.rename(columns={'frase_txt_x': 'input_txt', 'frase_txt_y': 'target_txt'})\n",
    "\n",
    "input_target['input_txt_split']  = input_target['input_txt'].map(string_split)\n",
    "input_target['target_txt_split'] = input_target['target_txt'].map(lambda x: string_split(x, True))\n",
    "\n",
    "input_target.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58d08b65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T20:47:14.861295Z",
     "iopub.status.busy": "2022-08-11T20:47:14.860260Z",
     "iopub.status.idle": "2022-08-11T20:47:15.083855Z",
     "shell.execute_reply": "2022-08-11T20:47:15.082298Z"
    },
    "papermill": {
     "duration": 0.238341,
     "end_time": "2022-08-11T20:47:15.086687",
     "exception": false,
     "start_time": "2022-08-11T20:47:14.848346",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "До удаления пустых строчек: 221616\n",
      "После удаления пустых строчек: 221293 Разница: 323\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_txt</th>\n",
       "      <th>target_txt</th>\n",
       "      <th>input_txt_split</th>\n",
       "      <th>target_txt_split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Can we make this quick?  Roxanne Korrine and A...</td>\n",
       "      <td>Well I thought we'd start with pronunciation i...</td>\n",
       "      <td>[C, a, n,  , w, e,  , m, a, k, e,  , t, h, i, ...</td>\n",
       "      <td>[&lt;START&gt;, W, e, l, l,  , I,  , t, h, o, u, g, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Well I thought we'd start with pronunciation i...</td>\n",
       "      <td>Not the hacking and gagging and spitting part....</td>\n",
       "      <td>[W, e, l, l,  , I,  , t, h, o, u, g, h, t,  , ...</td>\n",
       "      <td>[&lt;START&gt;, N, o, t,  , t, h, e,  , h, a, c, k, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not the hacking and gagging and spitting part....</td>\n",
       "      <td>Okay... then how 'bout we try out some French ...</td>\n",
       "      <td>[N, o, t,  , t, h, e,  , h, a, c, k, i, n, g, ...</td>\n",
       "      <td>[&lt;START&gt;, O, k, a, y, ., ., .,  , t, h, e, n, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           input_txt  \\\n",
       "0  Can we make this quick?  Roxanne Korrine and A...   \n",
       "1  Well I thought we'd start with pronunciation i...   \n",
       "2  Not the hacking and gagging and spitting part....   \n",
       "\n",
       "                                          target_txt  \\\n",
       "0  Well I thought we'd start with pronunciation i...   \n",
       "1  Not the hacking and gagging and spitting part....   \n",
       "2  Okay... then how 'bout we try out some French ...   \n",
       "\n",
       "                                     input_txt_split  \\\n",
       "0  [C, a, n,  , w, e,  , m, a, k, e,  , t, h, i, ...   \n",
       "1  [W, e, l, l,  , I,  , t, h, o, u, g, h, t,  , ...   \n",
       "2  [N, o, t,  , t, h, e,  , h, a, c, k, i, n, g, ...   \n",
       "\n",
       "                                    target_txt_split  \n",
       "0  [<START>, W, e, l, l,  , I,  , t, h, o, u, g, ...  \n",
       "1  [<START>, N, o, t,  , t, h, e,  , h, a, c, k, ...  \n",
       "2  [<START>, O, k, a, y, ., ., .,  , t, h, e, n, ...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_1 = input_target.shape[0]\n",
    "\n",
    "print('До удаления пустых строчек:', size_1)\n",
    "# Часть диалогов нет первой фразы \\ ответной фразы\n",
    "input_target = input_target.drop(index=input_target[input_target['input_txt'] == ''].index)\n",
    "input_target = input_target.drop(index=input_target[input_target['target_txt'] == ''].index)\n",
    "\n",
    "size_2 = input_target.shape[0]\n",
    "print('После удаления пустых строчек:', size_2, 'Разница:', size_1 - size_2)\n",
    "\n",
    "input_target.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca27be3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T20:47:15.109930Z",
     "iopub.status.busy": "2022-08-11T20:47:15.109263Z",
     "iopub.status.idle": "2022-08-11T20:47:15.346316Z",
     "shell.execute_reply": "2022-08-11T20:47:15.344957Z"
    },
    "papermill": {
     "duration": 0.251888,
     "end_time": "2022-08-11T20:47:15.349343",
     "exception": false,
     "start_time": "2022-08-11T20:47:15.097455",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180 187\n"
     ]
    }
   ],
   "source": [
    "# Фильтрация - три сигмы\n",
    "len_input_txt = []\n",
    "for i in input_target['input_txt']:\n",
    "    len_input_txt.append(len(i))\n",
    "\n",
    "input_limit = int(np.std(len_input_txt) * 3)\n",
    "\n",
    "len_target_txt = []\n",
    "for i in input_target['target_txt']:\n",
    "    len_input_txt.append(len(i))\n",
    "\n",
    "target_limit = int(np.std(len_input_txt) * 3)\n",
    "\n",
    "print(input_limit, target_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ecbcebba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T20:47:15.373721Z",
     "iopub.status.busy": "2022-08-11T20:47:15.372996Z",
     "iopub.status.idle": "2022-08-11T20:47:15.680106Z",
     "shell.execute_reply": "2022-08-11T20:47:15.678989Z"
    },
    "papermill": {
     "duration": 0.32155,
     "end_time": "2022-08-11T20:47:15.682455",
     "exception": false,
     "start_time": "2022-08-11T20:47:15.360905",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "До удаления слишком длинных диалогов: 221293\n",
      "После удаления строчек: 207858 Разница: 13435\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_txt</th>\n",
       "      <th>target_txt</th>\n",
       "      <th>input_txt_split</th>\n",
       "      <th>target_txt_split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Can we make this quick?  Roxanne Korrine and A...</td>\n",
       "      <td>Well I thought we'd start with pronunciation i...</td>\n",
       "      <td>[C, a, n,  , w, e,  , m, a, k, e,  , t, h, i, ...</td>\n",
       "      <td>[&lt;START&gt;, W, e, l, l,  , I,  , t, h, o, u, g, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Well I thought we'd start with pronunciation i...</td>\n",
       "      <td>Not the hacking and gagging and spitting part....</td>\n",
       "      <td>[W, e, l, l,  , I,  , t, h, o, u, g, h, t,  , ...</td>\n",
       "      <td>[&lt;START&gt;, N, o, t,  , t, h, e,  , h, a, c, k, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not the hacking and gagging and spitting part....</td>\n",
       "      <td>Okay... then how 'bout we try out some French ...</td>\n",
       "      <td>[N, o, t,  , t, h, e,  , h, a, c, k, i, n, g, ...</td>\n",
       "      <td>[&lt;START&gt;, O, k, a, y, ., ., .,  , t, h, e, n, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           input_txt  \\\n",
       "0  Can we make this quick?  Roxanne Korrine and A...   \n",
       "1  Well I thought we'd start with pronunciation i...   \n",
       "2  Not the hacking and gagging and spitting part....   \n",
       "\n",
       "                                          target_txt  \\\n",
       "0  Well I thought we'd start with pronunciation i...   \n",
       "1  Not the hacking and gagging and spitting part....   \n",
       "2  Okay... then how 'bout we try out some French ...   \n",
       "\n",
       "                                     input_txt_split  \\\n",
       "0  [C, a, n,  , w, e,  , m, a, k, e,  , t, h, i, ...   \n",
       "1  [W, e, l, l,  , I,  , t, h, o, u, g, h, t,  , ...   \n",
       "2  [N, o, t,  , t, h, e,  , h, a, c, k, i, n, g, ...   \n",
       "\n",
       "                                    target_txt_split  \n",
       "0  [<START>, W, e, l, l,  , I,  , t, h, o, u, g, ...  \n",
       "1  [<START>, N, o, t,  , t, h, e,  , h, a, c, k, ...  \n",
       "2  [<START>, O, k, a, y, ., ., .,  , t, h, e, n, ...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# отфильтруем значения установив лимит в 200\n",
    "# для таргета -1 т.к. добавляем теги\n",
    "size_1 = input_target.shape[0]\n",
    "print('До удаления слишком длинных диалогов:', size_1)\n",
    "input_target = input_target.drop(input_target[input_target['input_txt'].map(len) > 200].index) #input_limit   #60\n",
    "input_target = input_target.drop(input_target[input_target['target_txt'].map(len) > 200-1].index) #target_limit #60\n",
    "size_2 = input_target.shape[0]\n",
    "print('После удаления строчек:', size_2, 'Разница:', size_1 - size_2)\n",
    "\n",
    "# Сбросить индексацию\n",
    "input_target = input_target.reset_index(drop=True)\n",
    "input_target.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56275822",
   "metadata": {
    "papermill": {
     "duration": 0.0109,
     "end_time": "2022-08-11T20:47:15.704870",
     "exception": false,
     "start_time": "2022-08-11T20:47:15.693970",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2.4 Кодируем данные и создаём dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d780aa",
   "metadata": {
    "papermill": {
     "duration": 0.010675,
     "end_time": "2022-08-11T20:47:15.726761",
     "exception": false,
     "start_time": "2022-08-11T20:47:15.716086",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 2.4.1 Кодировщик и пример работы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0302ab7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T20:47:15.750465Z",
     "iopub.status.busy": "2022-08-11T20:47:15.750098Z",
     "iopub.status.idle": "2022-08-11T20:47:17.183133Z",
     "shell.execute_reply": "2022-08-11T20:47:17.181696Z"
    },
    "papermill": {
     "duration": 1.448211,
     "end_time": "2022-08-11T20:47:17.185730",
     "exception": false,
     "start_time": "2022-08-11T20:47:15.737519",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-11 20:47:17.137836: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "# Общий список - весь текст\n",
    "df_text = ' '.join(df_frase['frase_txt'].tolist())\n",
    "\n",
    "# Перечень символов\n",
    "vocab = sorted(set(df_text))\n",
    "vocab.append('<START>')\n",
    "vocab.append('<END>')\n",
    "\n",
    "# Отличается от TextVectorization тем, что нет возможности очищать данные и разделять данные.\n",
    "# ⚠️Кодирование Символов в Индексы\n",
    "ids_from_chars = tf.keras.layers.StringLookup(vocabulary=list(vocab), mask_token=None)\n",
    "# ⚠️Кодирование Индексов в символы\n",
    "chars_from_ids = tf.keras.layers.StringLookup(vocabulary=list(vocab), mask_token=None, invert=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04cded34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T20:47:17.210230Z",
     "iopub.status.busy": "2022-08-11T20:47:17.209848Z",
     "iopub.status.idle": "2022-08-11T20:47:17.214023Z",
     "shell.execute_reply": "2022-08-11T20:47:17.213255Z"
    },
    "papermill": {
     "duration": 0.018612,
     "end_time": "2022-08-11T20:47:17.215964",
     "exception": false,
     "start_time": "2022-08-11T20:47:17.197352",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def string_join(ids):\n",
    "  return tf.strings.reduce_join(ids, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e89a7ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T20:47:17.240425Z",
     "iopub.status.busy": "2022-08-11T20:47:17.239465Z",
     "iopub.status.idle": "2022-08-11T20:47:17.262527Z",
     "shell.execute_reply": "2022-08-11T20:47:17.261371Z"
    },
    "papermill": {
     "duration": 0.038158,
     "end_time": "2022-08-11T20:47:17.265303",
     "exception": false,
     "start_time": "2022-08-11T20:47:17.227145",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Словарь: ['[UNK]', ' ', '!', '\"', '#', '$', '%', '&', \"'\", ')']\n",
      "Длина словаря: 127\n",
      "Кодирование строчки: tf.Tensor(\n",
      "[125  54  67  74  74   1  40   1  82  70  77  83  69  70  82   1  85  67\n",
      "   8  66   1  81  82  63  80  82   1  85  71  82  70   1  78  80  77  76\n",
      "  83  76  65  71  63  82  71  77  76   1  71  68   1  82  70  63  82   8\n",
      "  81   1  77  73  63  87   1  85  71  82  70   1  87  77  83  14 126], shape=(71,), dtype=int64)\n",
      "Декодированая строчка:\n",
      " tf.Tensor(b\"<START>Well I thought we'd start with pronunciation if that's okay with you.<END>\", shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "# Пример работы созданного слоя\n",
    "print('Словарь:', ids_from_chars.get_vocabulary()[:10])\n",
    "print('Длина словаря:', len(ids_from_chars.get_vocabulary()))\n",
    "\n",
    "# Сохранение гиперпараметра\n",
    "HP_DATASET['vocab_size'] = len(ids_from_chars.get_vocabulary())\n",
    "\n",
    "# Кодирование строчки\n",
    "encoded_example = input_target['target_txt_split'][0]\n",
    "# ⚠️ Вначале разделение на элементы\n",
    "encoded_example = string_split(encoded_example)\n",
    "encoded_example = ids_from_chars(encoded_example)\n",
    "print('Кодирование строчки:', encoded_example)\n",
    "\n",
    "# Декодирование строчки\n",
    "decoded_example = chars_from_ids(encoded_example)\n",
    "# ⚠️ В конце сборка в строчку\n",
    "decoded_example = string_join(decoded_example)\n",
    "print('Декодированая строчка:\\n', decoded_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daafe8be",
   "metadata": {
    "papermill": {
     "duration": 0.011151,
     "end_time": "2022-08-11T20:47:17.287940",
     "exception": false,
     "start_time": "2022-08-11T20:47:17.276789",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 2.4.2 Сохранение кодироващиков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c540b8e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T20:47:17.312987Z",
     "iopub.status.busy": "2022-08-11T20:47:17.311809Z",
     "iopub.status.idle": "2022-08-11T20:47:17.849137Z",
     "shell.execute_reply": "2022-08-11T20:47:17.848024Z"
    },
    "papermill": {
     "duration": 0.552966,
     "end_time": "2022-08-11T20:47:17.852101",
     "exception": false,
     "start_time": "2022-08-11T20:47:17.299135",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "string_lookup (StringLookup) (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 0\n",
      "Trainable params: 0\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-11 20:47:17.552983: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    }
   ],
   "source": [
    "# Создание модели из одного слоя (кодировщик)\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.Input(shape=(1,), dtype=tf.string))\n",
    "model.add(ids_from_chars)\n",
    "model.summary()\n",
    "\n",
    "# Сохранение модели\n",
    "path = str(path_models / filename_model_ids_from_chars)\n",
    "model.save(path, save_format=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "867c7690",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T20:47:17.877711Z",
     "iopub.status.busy": "2022-08-11T20:47:17.877122Z",
     "iopub.status.idle": "2022-08-11T20:47:18.156449Z",
     "shell.execute_reply": "2022-08-11T20:47:18.155331Z"
    },
    "papermill": {
     "duration": 0.294994,
     "end_time": "2022-08-11T20:47:18.159230",
     "exception": false,
     "start_time": "2022-08-11T20:47:17.864236",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "string_lookup_1 (StringLooku (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 0\n",
      "Trainable params: 0\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Создание модели из одного слоя (кодировщик)\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.Input(shape=(1,), dtype=tf.int32))\n",
    "model.add(chars_from_ids)\n",
    "model.summary()\n",
    "\n",
    "# Сохранение модели\n",
    "path = str(path_models / filename_model_chars_from_ids)\n",
    "model.save(path, save_format=\"tf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76afa8c1",
   "metadata": {
    "papermill": {
     "duration": 0.011324,
     "end_time": "2022-08-11T20:47:18.182744",
     "exception": false,
     "start_time": "2022-08-11T20:47:18.171420",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 2.4.3 Подготовка последовательностей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f2836da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T20:47:18.207877Z",
     "iopub.status.busy": "2022-08-11T20:47:18.207204Z",
     "iopub.status.idle": "2022-08-11T20:47:18.227297Z",
     "shell.execute_reply": "2022-08-11T20:47:18.226182Z"
    },
    "papermill": {
     "duration": 0.035219,
     "end_time": "2022-08-11T20:47:18.229551",
     "exception": false,
     "start_time": "2022-08-11T20:47:18.194332",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_txt</th>\n",
       "      <th>target_txt</th>\n",
       "      <th>input_txt_split</th>\n",
       "      <th>target_txt_split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Can we make this quick?  Roxanne Korrine and A...</td>\n",
       "      <td>Well I thought we'd start with pronunciation i...</td>\n",
       "      <td>[C, a, n,  , w, e,  , m, a, k, e,  , t, h, i, ...</td>\n",
       "      <td>[&lt;START&gt;, W, e, l, l,  , I,  , t, h, o, u, g, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Well I thought we'd start with pronunciation i...</td>\n",
       "      <td>Not the hacking and gagging and spitting part....</td>\n",
       "      <td>[W, e, l, l,  , I,  , t, h, o, u, g, h, t,  , ...</td>\n",
       "      <td>[&lt;START&gt;, N, o, t,  , t, h, e,  , h, a, c, k, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not the hacking and gagging and spitting part....</td>\n",
       "      <td>Okay... then how 'bout we try out some French ...</td>\n",
       "      <td>[N, o, t,  , t, h, e,  , h, a, c, k, i, n, g, ...</td>\n",
       "      <td>[&lt;START&gt;, O, k, a, y, ., ., .,  , t, h, e, n, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You're asking me out.  That's so cute. What's ...</td>\n",
       "      <td>Forget it.</td>\n",
       "      <td>[Y, o, u, ', r, e,  , a, s, k, i, n, g,  , m, ...</td>\n",
       "      <td>[&lt;START&gt;, F, o, r, g, e, t,  , i, t, ., &lt;END&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No no it's my fault -- we didn't have a proper...</td>\n",
       "      <td>Cameron.</td>\n",
       "      <td>[N, o,  , n, o,  , i, t, ', s,  , m, y,  , f, ...</td>\n",
       "      <td>[&lt;START&gt;, C, a, m, e, r, o, n, ., &lt;END&gt;]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           input_txt  \\\n",
       "0  Can we make this quick?  Roxanne Korrine and A...   \n",
       "1  Well I thought we'd start with pronunciation i...   \n",
       "2  Not the hacking and gagging and spitting part....   \n",
       "3  You're asking me out.  That's so cute. What's ...   \n",
       "4  No no it's my fault -- we didn't have a proper...   \n",
       "\n",
       "                                          target_txt  \\\n",
       "0  Well I thought we'd start with pronunciation i...   \n",
       "1  Not the hacking and gagging and spitting part....   \n",
       "2  Okay... then how 'bout we try out some French ...   \n",
       "3                                         Forget it.   \n",
       "4                                           Cameron.   \n",
       "\n",
       "                                     input_txt_split  \\\n",
       "0  [C, a, n,  , w, e,  , m, a, k, e,  , t, h, i, ...   \n",
       "1  [W, e, l, l,  , I,  , t, h, o, u, g, h, t,  , ...   \n",
       "2  [N, o, t,  , t, h, e,  , h, a, c, k, i, n, g, ...   \n",
       "3  [Y, o, u, ', r, e,  , a, s, k, i, n, g,  , m, ...   \n",
       "4  [N, o,  , n, o,  , i, t, ', s,  , m, y,  , f, ...   \n",
       "\n",
       "                                    target_txt_split  \n",
       "0  [<START>, W, e, l, l,  , I,  , t, h, o, u, g, ...  \n",
       "1  [<START>, N, o, t,  , t, h, e,  , h, a, c, k, ...  \n",
       "2  [<START>, O, k, a, y, ., ., .,  , t, h, e, n, ...  \n",
       "3     [<START>, F, o, r, g, e, t,  , i, t, ., <END>]  \n",
       "4           [<START>, C, a, m, e, r, o, n, ., <END>]  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ce531910",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T20:47:18.255465Z",
     "iopub.status.busy": "2022-08-11T20:47:18.255066Z",
     "iopub.status.idle": "2022-08-11T20:51:14.402068Z",
     "shell.execute_reply": "2022-08-11T20:51:14.401003Z"
    },
    "papermill": {
     "duration": 236.162821,
     "end_time": "2022-08-11T20:51:14.404539",
     "exception": false,
     "start_time": "2022-08-11T20:47:18.241718",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 31s, sys: 393 ms, total: 1min 31s\n",
      "Wall time: 1min 31s\n",
      "CPU times: user 1min 30s, sys: 430 ms, total: 1min 31s\n",
      "Wall time: 1min 31s\n",
      "CPU times: user 26.4 s, sys: 281 ms, total: 26.7 s\n",
      "Wall time: 26.7 s\n",
      "CPU times: user 25.8 s, sys: 250 ms, total: 26 s\n",
      "Wall time: 26 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_txt</th>\n",
       "      <th>target_txt</th>\n",
       "      <th>input_txt_split</th>\n",
       "      <th>target_txt_split</th>\n",
       "      <th>encoder_input_seq</th>\n",
       "      <th>decoder_input</th>\n",
       "      <th>decoder_input_seq</th>\n",
       "      <th>decoder_target_seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Can we make this quick?  Roxanne Korrine and A...</td>\n",
       "      <td>Well I thought we'd start with pronunciation i...</td>\n",
       "      <td>[C, a, n,  , w, e,  , m, a, k, e,  , t, h, i, ...</td>\n",
       "      <td>[&lt;START&gt;, W, e, l, l,  , I,  , t, h, o, u, g, ...</td>\n",
       "      <td>(tf.Tensor(34, shape=(), dtype=int64), tf.Tens...</td>\n",
       "      <td>(tf.Tensor(125, shape=(), dtype=int64), tf.Ten...</td>\n",
       "      <td>(tf.Tensor(125, shape=(), dtype=int64), tf.Ten...</td>\n",
       "      <td>(tf.Tensor(54, shape=(), dtype=int64), tf.Tens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Well I thought we'd start with pronunciation i...</td>\n",
       "      <td>Not the hacking and gagging and spitting part....</td>\n",
       "      <td>[W, e, l, l,  , I,  , t, h, o, u, g, h, t,  , ...</td>\n",
       "      <td>[&lt;START&gt;, N, o, t,  , t, h, e,  , h, a, c, k, ...</td>\n",
       "      <td>(tf.Tensor(54, shape=(), dtype=int64), tf.Tens...</td>\n",
       "      <td>(tf.Tensor(125, shape=(), dtype=int64), tf.Ten...</td>\n",
       "      <td>(tf.Tensor(125, shape=(), dtype=int64), tf.Ten...</td>\n",
       "      <td>(tf.Tensor(45, shape=(), dtype=int64), tf.Tens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not the hacking and gagging and spitting part....</td>\n",
       "      <td>Okay... then how 'bout we try out some French ...</td>\n",
       "      <td>[N, o, t,  , t, h, e,  , h, a, c, k, i, n, g, ...</td>\n",
       "      <td>[&lt;START&gt;, O, k, a, y, ., ., .,  , t, h, e, n, ...</td>\n",
       "      <td>(tf.Tensor(45, shape=(), dtype=int64), tf.Tens...</td>\n",
       "      <td>(tf.Tensor(125, shape=(), dtype=int64), tf.Ten...</td>\n",
       "      <td>(tf.Tensor(125, shape=(), dtype=int64), tf.Ten...</td>\n",
       "      <td>(tf.Tensor(46, shape=(), dtype=int64), tf.Tens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You're asking me out.  That's so cute. What's ...</td>\n",
       "      <td>Forget it.</td>\n",
       "      <td>[Y, o, u, ', r, e,  , a, s, k, i, n, g,  , m, ...</td>\n",
       "      <td>[&lt;START&gt;, F, o, r, g, e, t,  , i, t, ., &lt;END&gt;]</td>\n",
       "      <td>(tf.Tensor(56, shape=(), dtype=int64), tf.Tens...</td>\n",
       "      <td>(tf.Tensor(125, shape=(), dtype=int64), tf.Ten...</td>\n",
       "      <td>(tf.Tensor(125, shape=(), dtype=int64), tf.Ten...</td>\n",
       "      <td>(tf.Tensor(37, shape=(), dtype=int64), tf.Tens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No no it's my fault -- we didn't have a proper...</td>\n",
       "      <td>Cameron.</td>\n",
       "      <td>[N, o,  , n, o,  , i, t, ', s,  , m, y,  , f, ...</td>\n",
       "      <td>[&lt;START&gt;, C, a, m, e, r, o, n, ., &lt;END&gt;]</td>\n",
       "      <td>(tf.Tensor(45, shape=(), dtype=int64), tf.Tens...</td>\n",
       "      <td>(tf.Tensor(125, shape=(), dtype=int64), tf.Ten...</td>\n",
       "      <td>(tf.Tensor(125, shape=(), dtype=int64), tf.Ten...</td>\n",
       "      <td>(tf.Tensor(34, shape=(), dtype=int64), tf.Tens...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           input_txt  \\\n",
       "0  Can we make this quick?  Roxanne Korrine and A...   \n",
       "1  Well I thought we'd start with pronunciation i...   \n",
       "2  Not the hacking and gagging and spitting part....   \n",
       "3  You're asking me out.  That's so cute. What's ...   \n",
       "4  No no it's my fault -- we didn't have a proper...   \n",
       "\n",
       "                                          target_txt  \\\n",
       "0  Well I thought we'd start with pronunciation i...   \n",
       "1  Not the hacking and gagging and spitting part....   \n",
       "2  Okay... then how 'bout we try out some French ...   \n",
       "3                                         Forget it.   \n",
       "4                                           Cameron.   \n",
       "\n",
       "                                     input_txt_split  \\\n",
       "0  [C, a, n,  , w, e,  , m, a, k, e,  , t, h, i, ...   \n",
       "1  [W, e, l, l,  , I,  , t, h, o, u, g, h, t,  , ...   \n",
       "2  [N, o, t,  , t, h, e,  , h, a, c, k, i, n, g, ...   \n",
       "3  [Y, o, u, ', r, e,  , a, s, k, i, n, g,  , m, ...   \n",
       "4  [N, o,  , n, o,  , i, t, ', s,  , m, y,  , f, ...   \n",
       "\n",
       "                                    target_txt_split  \\\n",
       "0  [<START>, W, e, l, l,  , I,  , t, h, o, u, g, ...   \n",
       "1  [<START>, N, o, t,  , t, h, e,  , h, a, c, k, ...   \n",
       "2  [<START>, O, k, a, y, ., ., .,  , t, h, e, n, ...   \n",
       "3     [<START>, F, o, r, g, e, t,  , i, t, ., <END>]   \n",
       "4           [<START>, C, a, m, e, r, o, n, ., <END>]   \n",
       "\n",
       "                                   encoder_input_seq  \\\n",
       "0  (tf.Tensor(34, shape=(), dtype=int64), tf.Tens...   \n",
       "1  (tf.Tensor(54, shape=(), dtype=int64), tf.Tens...   \n",
       "2  (tf.Tensor(45, shape=(), dtype=int64), tf.Tens...   \n",
       "3  (tf.Tensor(56, shape=(), dtype=int64), tf.Tens...   \n",
       "4  (tf.Tensor(45, shape=(), dtype=int64), tf.Tens...   \n",
       "\n",
       "                                       decoder_input  \\\n",
       "0  (tf.Tensor(125, shape=(), dtype=int64), tf.Ten...   \n",
       "1  (tf.Tensor(125, shape=(), dtype=int64), tf.Ten...   \n",
       "2  (tf.Tensor(125, shape=(), dtype=int64), tf.Ten...   \n",
       "3  (tf.Tensor(125, shape=(), dtype=int64), tf.Ten...   \n",
       "4  (tf.Tensor(125, shape=(), dtype=int64), tf.Ten...   \n",
       "\n",
       "                                   decoder_input_seq  \\\n",
       "0  (tf.Tensor(125, shape=(), dtype=int64), tf.Ten...   \n",
       "1  (tf.Tensor(125, shape=(), dtype=int64), tf.Ten...   \n",
       "2  (tf.Tensor(125, shape=(), dtype=int64), tf.Ten...   \n",
       "3  (tf.Tensor(125, shape=(), dtype=int64), tf.Ten...   \n",
       "4  (tf.Tensor(125, shape=(), dtype=int64), tf.Ten...   \n",
       "\n",
       "                                  decoder_target_seq  \n",
       "0  (tf.Tensor(54, shape=(), dtype=int64), tf.Tens...  \n",
       "1  (tf.Tensor(45, shape=(), dtype=int64), tf.Tens...  \n",
       "2  (tf.Tensor(46, shape=(), dtype=int64), tf.Tens...  \n",
       "3  (tf.Tensor(37, shape=(), dtype=int64), tf.Tens...  \n",
       "4  (tf.Tensor(34, shape=(), dtype=int64), tf.Tens...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Получаем вход для энкодера: Кодируем столбец (str) в int\n",
    "%time input_target['encoder_input_seq']  = input_target['input_txt_split'].map(ids_from_chars)\n",
    "\n",
    "# Получаем вход и выход для декодера: Кодируем столбец (str) в int\n",
    "%time input_target['decoder_input']  = input_target['target_txt_split'].map(ids_from_chars)\n",
    "# Разделяем на два набора, со смещением: в первом <START> (125); во вотором <END>(id=126)\n",
    "%time input_target['decoder_input_seq']  = input_target['decoder_input'].map(lambda x: x[:-1])\n",
    "%time input_target['decoder_target_seq'] = input_target['decoder_input'].map(lambda x: x[1:])\n",
    "\n",
    "input_target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ee74dab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T20:51:14.431414Z",
     "iopub.status.busy": "2022-08-11T20:51:14.430745Z",
     "iopub.status.idle": "2022-08-11T20:51:15.724427Z",
     "shell.execute_reply": "2022-08-11T20:51:15.723299Z"
    },
    "papermill": {
     "duration": 1.309457,
     "end_time": "2022-08-11T20:51:15.726797",
     "exception": false,
     "start_time": "2022-08-11T20:51:14.417340",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_target['decoder_input_seq'].map(len).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7b01a770",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T20:51:15.755127Z",
     "iopub.status.busy": "2022-08-11T20:51:15.754735Z",
     "iopub.status.idle": "2022-08-11T20:52:48.208817Z",
     "shell.execute_reply": "2022-08-11T20:52:48.207595Z"
    },
    "papermill": {
     "duration": 92.483798,
     "end_time": "2022-08-11T20:52:48.224060",
     "exception": false,
     "start_time": "2022-08-11T20:51:15.740262",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.2 s, sys: 88.7 ms, total: 31.3 s\n",
      "Wall time: 31.3 s\n",
      "CPU times: user 29.8 s, sys: 43.9 ms, total: 29.9 s\n",
      "Wall time: 29.9 s\n",
      "CPU times: user 31.1 s, sys: 103 ms, total: 31.2 s\n",
      "Wall time: 31.2 s\n"
     ]
    }
   ],
   "source": [
    "# Добавляем паддинги, без maxlen padding input = 180, target = 188, ⚠️было 190, изменил на 60 maxlen=200, \n",
    "# tf.keras.utils.pad_sequences() # 2.9\n",
    "encoder_input_seq = input_target['encoder_input_seq']\n",
    "%time encoder_input_seq = tf.keras.preprocessing.sequence.pad_sequences(encoder_input_seq, padding=\"post\")\n",
    "\n",
    "decoder_input_seq = input_target['decoder_input_seq']\n",
    "%time decoder_input_seq = tf.keras.preprocessing.sequence.pad_sequences(decoder_input_seq, padding=\"post\")\n",
    "\n",
    "decoder_target_seq = input_target['decoder_target_seq']\n",
    "%time decoder_target_seq = tf.keras.preprocessing.sequence.pad_sequences(decoder_target_seq, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "31f7dde3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T20:52:48.251392Z",
     "iopub.status.busy": "2022-08-11T20:52:48.250675Z",
     "iopub.status.idle": "2022-08-11T20:52:49.247104Z",
     "shell.execute_reply": "2022-08-11T20:52:49.245887Z"
    },
    "papermill": {
     "duration": 1.013481,
     "end_time": "2022-08-11T20:52:49.250059",
     "exception": false,
     "start_time": "2022-08-11T20:52:48.236578",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(200,), dtype=int32, numpy=\n",
      "array([34, 63, 76,  1, 85, 67,  1, 75, 63, 73, 67,  1, 82, 70, 71, 81,  1,\n",
      "       79, 83, 71, 65, 73, 31,  1,  1, 49, 77, 86, 63, 76, 76, 67,  1, 42,\n",
      "       77, 80, 80, 71, 76, 67,  1, 63, 76, 66,  1, 32, 76, 66, 80, 67, 85,\n",
      "        1, 33, 63, 80, 80, 67, 82, 82,  1, 63, 80, 67,  1, 70, 63, 84, 71,\n",
      "       76, 69,  1, 63, 76,  1, 71, 76, 65, 80, 67, 66, 71, 64, 74, 87,  1,\n",
      "       70, 77, 80, 80, 67, 76, 66, 77, 83, 81,  1, 78, 83, 64, 74, 71, 65,\n",
      "        1, 64, 80, 67, 63, 73, 13,  1, 83, 78,  1, 77, 76,  1, 82, 70, 67,\n",
      "        1, 79, 83, 63, 66, 14,  1,  1, 32, 69, 63, 71, 76, 14,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0], dtype=int32)>, <tf.Tensor: shape=(200,), dtype=int32, numpy=\n",
      "array([125,  54,  67,  74,  74,   1,  40,   1,  82,  70,  77,  83,  69,\n",
      "        70,  82,   1,  85,  67,   8,  66,   1,  81,  82,  63,  80,  82,\n",
      "         1,  85,  71,  82,  70,   1,  78,  80,  77,  76,  83,  76,  65,\n",
      "        71,  63,  82,  71,  77,  76,   1,  71,  68,   1,  82,  70,  63,\n",
      "        82,   8,  81,   1,  77,  73,  63,  87,   1,  85,  71,  82,  70,\n",
      "         1,  87,  77,  83,  14,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0], dtype=int32)>, <tf.Tensor: shape=(200,), dtype=int32, numpy=\n",
      "array([ 54,  67,  74,  74,   1,  40,   1,  82,  70,  77,  83,  69,  70,\n",
      "        82,   1,  85,  67,   8,  66,   1,  81,  82,  63,  80,  82,   1,\n",
      "        85,  71,  82,  70,   1,  78,  80,  77,  76,  83,  76,  65,  71,\n",
      "        63,  82,  71,  77,  76,   1,  71,  68,   1,  82,  70,  63,  82,\n",
      "         8,  81,   1,  77,  73,  63,  87,   1,  85,  71,  82,  70,   1,\n",
      "        87,  77,  83,  14, 126,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0], dtype=int32)>)\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((encoder_input_seq,  decoder_input_seq, decoder_target_seq))\n",
    "\n",
    "for i in dataset.take(1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084e86a3",
   "metadata": {
    "papermill": {
     "duration": 0.012772,
     "end_time": "2022-08-11T20:52:49.278055",
     "exception": false,
     "start_time": "2022-08-11T20:52:49.265283",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2.5 Сохраняем Dataset -> TFRecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2793067b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T20:52:49.306400Z",
     "iopub.status.busy": "2022-08-11T20:52:49.305878Z",
     "iopub.status.idle": "2022-08-11T20:52:49.314908Z",
     "shell.execute_reply": "2022-08-11T20:52:49.313799Z"
    },
    "papermill": {
     "duration": 0.025845,
     "end_time": "2022-08-11T20:52:49.317083",
     "exception": false,
     "start_time": "2022-08-11T20:52:49.291238",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bytes_feature(seq):\n",
    "  if isinstance(seq, type(tf.constant(0))):\n",
    "    seq = seq.numpy()\n",
    "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[seq]))\n",
    "\n",
    "def create_record(encode_input_seqs, decode_input_seqs, decode_target_seqs):\n",
    "    feature = {\n",
    "        'encode_input_seqs'  : encode_input_seqs,\n",
    "        'decode_input_seqs'  : decode_input_seqs,\n",
    "        'decode_target_seqs' : decode_target_seqs,\n",
    "      }\n",
    "    proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    return proto.SerializeToString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d9f73c42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T20:52:49.346137Z",
     "iopub.status.busy": "2022-08-11T20:52:49.345187Z",
     "iopub.status.idle": "2022-08-11T20:54:07.132232Z",
     "shell.execute_reply": "2022-08-11T20:54:07.130815Z"
    },
    "papermill": {
     "duration": 77.804442,
     "end_time": "2022-08-11T20:54:07.134633",
     "exception": false,
     "start_time": "2022-08-11T20:52:49.330191",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "20000\n",
      "40000\n",
      "60000\n",
      "80000\n",
      "100000\n",
      "120000\n",
      "140000\n",
      "160000\n",
      "180000\n",
      "200000\n",
      "dataset сохранён: data/input_target_ids_len200.tfrecords\n",
      "CPU times: user 1min 15s, sys: 2.46 s, total: 1min 17s\n",
      "Wall time: 1min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Сохраняем на диск\n",
    "path = str(path_data / filename_input_target_ids)\n",
    "\n",
    "with tf.io.TFRecordWriter(path) as writer:\n",
    "    num = 0\n",
    "    for sample in dataset:\n",
    "        if num % 20_000 == 0:\n",
    "            print(num)\n",
    "        num += 1\n",
    "        # ⚠️ Сериализация, нельзя записать список чисел \n",
    "        enI = tf.io.serialize_tensor(sample[0])\n",
    "        enI = bytes_feature(enI)\n",
    "\n",
    "        deI = tf.io.serialize_tensor(sample[1])\n",
    "        deI = bytes_feature(deI)\n",
    "\n",
    "        deT = tf.io.serialize_tensor(sample[2])\n",
    "        deT = bytes_feature(deT)\n",
    "\n",
    "        pr = create_record(enI, deI, deT)\n",
    "        writer.write(pr)\n",
    "\n",
    "    print(f'dataset сохранён: {path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "80cadd59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T20:54:07.164404Z",
     "iopub.status.busy": "2022-08-11T20:54:07.163671Z",
     "iopub.status.idle": "2022-08-11T20:54:07.170622Z",
     "shell.execute_reply": "2022-08-11T20:54:07.169871Z"
    },
    "papermill": {
     "duration": 0.024382,
     "end_time": "2022-08-11T20:54:07.172814",
     "exception": false,
     "start_time": "2022-08-11T20:54:07.148432",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Функция для чтения TFRecords\n",
    "feature_description = {\n",
    "        'encode_input_seqs'  : tf.io.FixedLenFeature([], tf.string, default_value=''),\n",
    "        'decode_input_seqs'  : tf.io.FixedLenFeature([], tf.string, default_value=''),\n",
    "        'decode_target_seqs' : tf.io.FixedLenFeature([], tf.string, default_value=''),\n",
    "          }\n",
    "\n",
    "def parse_function(example_proto):\n",
    "  parsed = tf.io.parse_single_example(example_proto, feature_description)\n",
    "  return (parsed['encode_input_seqs'], parsed['decode_input_seqs'], parsed['decode_target_seqs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e27791b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T20:54:07.202200Z",
     "iopub.status.busy": "2022-08-11T20:54:07.201411Z",
     "iopub.status.idle": "2022-08-11T20:54:08.403138Z",
     "shell.execute_reply": "2022-08-11T20:54:08.401900Z"
    },
    "papermill": {
     "duration": 1.219122,
     "end_time": "2022-08-11T20:54:08.405539",
     "exception": false,
     "start_time": "2022-08-11T20:54:07.186417",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 517424\r\n",
      "drwxr-xr-x 2 root root      4096 Aug 11 20:52 \u001b[0m\u001b[01;34m.\u001b[0m/\r\n",
      "drwxr-xr-x 7 root root      4096 Aug 11 20:47 \u001b[01;34m..\u001b[0m/\r\n",
      "-rw-r--r-- 1 root root 529830042 Aug 11 20:54 input_target_ids_len200.tfrecords\r\n"
     ]
    }
   ],
   "source": [
    "ls -all ./data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a78f1fbe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T20:54:08.435101Z",
     "iopub.status.busy": "2022-08-11T20:54:08.434637Z",
     "iopub.status.idle": "2022-08-11T20:54:50.709690Z",
     "shell.execute_reply": "2022-08-11T20:54:50.708313Z"
    },
    "papermill": {
     "duration": 42.304972,
     "end_time": "2022-08-11T20:54:50.724357",
     "exception": false,
     "start_time": "2022-08-11T20:54:08.419385",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-11 20:54:08.594003: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Набор объёмом: 207858\n",
      "(<tf.Tensor: shape=(200,), dtype=int32, numpy=\n",
      "array([34, 63, 76,  1, 85, 67,  1, 75, 63, 73, 67,  1, 82, 70, 71, 81,  1,\n",
      "       79, 83, 71, 65, 73, 31,  1,  1, 49, 77, 86, 63, 76, 76, 67,  1, 42,\n",
      "       77, 80, 80, 71, 76, 67,  1, 63, 76, 66,  1, 32, 76, 66, 80, 67, 85,\n",
      "        1, 33, 63, 80, 80, 67, 82, 82,  1, 63, 80, 67,  1, 70, 63, 84, 71,\n",
      "       76, 69,  1, 63, 76,  1, 71, 76, 65, 80, 67, 66, 71, 64, 74, 87,  1,\n",
      "       70, 77, 80, 80, 67, 76, 66, 77, 83, 81,  1, 78, 83, 64, 74, 71, 65,\n",
      "        1, 64, 80, 67, 63, 73, 13,  1, 83, 78,  1, 77, 76,  1, 82, 70, 67,\n",
      "        1, 79, 83, 63, 66, 14,  1,  1, 32, 69, 63, 71, 76, 14,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0], dtype=int32)>, <tf.Tensor: shape=(200,), dtype=int32, numpy=\n",
      "array([125,  54,  67,  74,  74,   1,  40,   1,  82,  70,  77,  83,  69,\n",
      "        70,  82,   1,  85,  67,   8,  66,   1,  81,  82,  63,  80,  82,\n",
      "         1,  85,  71,  82,  70,   1,  78,  80,  77,  76,  83,  76,  65,\n",
      "        71,  63,  82,  71,  77,  76,   1,  71,  68,   1,  82,  70,  63,\n",
      "        82,   8,  81,   1,  77,  73,  63,  87,   1,  85,  71,  82,  70,\n",
      "         1,  87,  77,  83,  14,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0], dtype=int32)>, <tf.Tensor: shape=(200,), dtype=int32, numpy=\n",
      "array([ 54,  67,  74,  74,   1,  40,   1,  82,  70,  77,  83,  69,  70,\n",
      "        82,   1,  85,  67,   8,  66,   1,  81,  82,  63,  80,  82,   1,\n",
      "        85,  71,  82,  70,   1,  78,  80,  77,  76,  83,  76,  65,  71,\n",
      "        63,  82,  71,  77,  76,   1,  71,  68,   1,  82,  70,  63,  82,\n",
      "         8,  81,   1,  77,  73,  63,  87,   1,  85,  71,  82,  70,   1,\n",
      "        87,  77,  83,  14, 126,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0], dtype=int32)>)\n"
     ]
    }
   ],
   "source": [
    "# Проверка записанных данных\n",
    "path = str(path_data / filename_input_target_ids)\n",
    "\n",
    "dataset = tf.data.TFRecordDataset(filenames = [path])\n",
    "dataset = dataset.map(parse_function)\n",
    "dataset = dataset.map(lambda x, y, z: [tf.io.parse_tensor(x, out_type=tf.int32), \n",
    "                                       tf.io.parse_tensor(y, out_type=tf.int32),\n",
    "                                       tf.io.parse_tensor(z, out_type=tf.int32)])\n",
    "\n",
    "len_tfr = []\n",
    "for i in dataset:\n",
    "    len_tfr.append(i)\n",
    "print('Набор объёмом:', len(len_tfr))\n",
    "\n",
    "for i in dataset.take(1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8524980f",
   "metadata": {
    "papermill": {
     "duration": 0.014106,
     "end_time": "2022-08-11T20:54:50.752407",
     "exception": false,
     "start_time": "2022-08-11T20:54:50.738301",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3 Сохранение результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ee487f76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T20:54:50.782347Z",
     "iopub.status.busy": "2022-08-11T20:54:50.781879Z",
     "iopub.status.idle": "2022-08-11T20:54:59.716387Z",
     "shell.execute_reply": "2022-08-11T20:54:59.715297Z"
    },
    "papermill": {
     "duration": 8.952297,
     "end_time": "2022-08-11T20:54:59.718768",
     "exception": false,
     "start_time": "2022-08-11T20:54:50.766471",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./models.zip'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.make_archive(base_name='./data', format='zip', base_dir='./data')\n",
    "shutil.make_archive(base_name='./models', format='zip', base_dir='./models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f08879af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T20:54:59.748898Z",
     "iopub.status.busy": "2022-08-11T20:54:59.748222Z",
     "iopub.status.idle": "2022-08-11T20:55:00.978242Z",
     "shell.execute_reply": "2022-08-11T20:55:00.977058Z"
    },
    "papermill": {
     "duration": 1.248059,
     "end_time": "2022-08-11T20:55:00.980992",
     "exception": false,
     "start_time": "2022-08-11T20:54:59.732933",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 17008\r\n",
      "drwxr-xr-x 7 root root     4096 Aug 11 20:54 .\r\n",
      "drwxr-xr-x 6 root root     4096 Aug 11 20:46 ..\r\n",
      "---------- 1 root root    85954 Aug 11 20:54 __notebook__.ipynb\r\n",
      "drwxr-xr-x 2 root root     4096 Aug 11 20:52 data\r\n",
      "-rw-r--r-- 1 root root 17282536 Aug 11 20:54 data.zip\r\n",
      "drwxr-xr-x 2 root root     4096 Aug 11 20:47 img\r\n",
      "drwxr-xr-x 2 root root     4096 Aug 11 20:47 mlruns\r\n",
      "drwxr-xr-x 6 root root     4096 Aug 11 20:47 models\r\n",
      "-rw-r--r-- 1 root root    14837 Aug 11 20:54 models.zip\r\n",
      "drwxr-xr-x 2 root root     4096 Aug 11 20:47 tblogs\r\n"
     ]
    }
   ],
   "source": [
    "!ls -all"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 490.210467,
   "end_time": "2022-08-11T20:55:03.821467",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-08-11T20:46:53.611000",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
